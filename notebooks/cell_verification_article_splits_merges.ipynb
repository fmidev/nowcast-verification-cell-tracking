{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eeb74a0-4805-4b49-978d-ddfbb3fb9b38",
   "metadata": {},
   "source": [
    "# Figure with number of splits and merges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f639b-dbc1-4f01-ae67-6d43664ad061",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63a9e0-45d3-463c-b593-1d1243323a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pysteps.visualization.spectral import plot_spectrum1d\n",
    "import geopandas as gpd\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib import colors, cm, gridspec, ticker\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from copy import copy\n",
    "import cmcrameri  # noqa\n",
    "import palettable  # noqa\n",
    "import textwrap\n",
    "import string\n",
    "import pandas as pd\n",
    "import xskillscore as xs\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "from flox.xarray import xarray_reduce\n",
    "\n",
    "alphabet = string.ascii_lowercase\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb5276-ef5f-4ab2-905f-25a96e8e2115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MEDIANPROPS = dict(linestyle=\"-\", linewidth=2, color=\"k\")\n",
    "MEANLINEPROPS = dict(linestyle=(0, (1,0.4)), linewidth=2, color=\"k\")\n",
    "FLIERPROPS = dict(marker=\"o\", markersize=0.3, markerfacecolor=\"gray\", markeredgecolor=\"gray\", rasterized=True)\n",
    "ZEROLINE_PROPS = dict(linestyle=\"--\", linewidth=1.5, color=\"gray\")\n",
    "\n",
    "\n",
    "STATE_GROUP_TITLES = {\n",
    "    \"growth\": \"Growing cells\",\n",
    "    \"decay\": \"Decaying cells\",\n",
    "    \"all\": \"All cells\",\n",
    "}\n",
    "\n",
    "HUE_CMAP = \"cmc.hawaii_r\"\n",
    "\n",
    "PLOT_EXT = \"png\"\n",
    "\n",
    "MAX_RR_LIMITS = (-125, 125)\n",
    "MEAN_RR_LIMITS = (-20, 20)\n",
    "SUM_RR_LIMITS = (-10, 20)\n",
    "LIFETIME_LIMITS = (-12, 12)\n",
    "AREA_LIMITS = (-600, 1000)\n",
    "COUNT_LIMITS = (0, 20000)\n",
    "CENTROID_DISTANCE_LIMITS = (0, 30)\n",
    "\n",
    "MAX_RR_TICK_MULTIPLE = 25\n",
    "MEAN_RR_TICK_MULTIPLE = 5\n",
    "SUM_RR_TICK_MULTIPLE = 5\n",
    "LIFETIME_TICK_MULTIPLE = 2\n",
    "AREA_TICK_MULTIPLE = 200\n",
    "COUNT_TICK_MULTIPLE = 1000\n",
    "\n",
    "MAX_RR_DIFF_TITLE = \"Difference in maximum rainfall rate [mm h$^{-1}$]\"\n",
    "MEAN_RR_DIFF_TITLE = \"Difference in mean rainfall rate [mm h$^{-1}$]\"\n",
    "SUM_RR_DIFF_TITLE = \"Difference in volume rain rate [10$^6$ m$^3$h$^{-1}$]\"\n",
    "LIFETIME_TITLE = \"Difference in lifetime [min]\"\n",
    "AREA_TITLE = \"Difference in area [km$^2$]\"\n",
    "COUNT_TITLE = \"Cell count [10$^3$]\"\n",
    "CENTROID_DISTANCE_TITLE = \"Centroid distance [km]\"\n",
    "\n",
    "METHOD_X_LABEL = \"Model\"\n",
    "\n",
    "W_PER_METHOD_LT = 1.2\n",
    "W_PER_METHOD_S = 0.8\n",
    "\n",
    "FIG_HEIGHT = 6\n",
    "FIG_WIDTH = 6\n",
    "\n",
    "HIST_FIG_H = 2.5\n",
    "HIST_FIG_W = 3\n",
    "\n",
    "# Cut away saturated values\n",
    "MAX_RR_LIMIT = 122\n",
    "\n",
    "# tolerance for zero difference for volume rain rate\n",
    "SUM_RR_ZERO_TOL = 0.0\n",
    "\n",
    "def leadtime_to_minutes(x, pos):\n",
    "    return f\"{x * 5:.0f}\"\n",
    "\n",
    "# Load stylefile\n",
    "plt.style.use(\n",
    "    \"../config/stylefiles/object_figs_article.mplstyle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e7a26-57f1-4375-bd97-7fda5b5cf956",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from addict import Dict\n",
    "import yaml\n",
    "\n",
    "\n",
    "def load_yaml_config(path: str):\n",
    "    \"\"\"\n",
    "    Load a YAML config file as an attribute-dictionnary.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the YAML config file.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Configuration loaded.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        config = Dict(yaml.safe_load(f))\n",
    "    return config\n",
    "\n",
    "\n",
    "def save_figs(fig, outpath, name, extensions, subfolder=None):\n",
    "    if subfolder:\n",
    "        outpath = outpath / subfolder\n",
    "        outpath.mkdir(parents=True, exist_ok=True)\n",
    "    for ext in extensions:\n",
    "        fig.savefig(outpath / f\"{name}.{ext}\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def create_fig_leadtime_groups(ngroups, nmethods):\n",
    "    return plt.subplots(\n",
    "        ncols=ngroups,\n",
    "        nrows=1,\n",
    "        # figsize=(W_PER_METHOD_S * N_METHODS, FIG_HEIGHT * len(groups)),\n",
    "        figsize=(FIG_WIDTH * ngroups, FIG_HEIGHT),\n",
    "        constrained_layout=True,\n",
    "        sharey=True,\n",
    "        squeeze=True\n",
    "    )\n",
    "\n",
    "def create_fig_hist(ngroups):\n",
    "    return plt.subplots(\n",
    "        ncols=ngroups,\n",
    "        nrows=1,\n",
    "        figsize=(HIST_FIG_W*ngroups, HIST_FIG_H),\n",
    "        constrained_layout=True,\n",
    "        sharey=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_obs_counts(obs_counts, axs, edgecolor=None, hue_cmap=None):\n",
    "    start = axs.containers[0].get_children()[0].xy[0] - 1\n",
    "    for i, val in enumerate(obs_counts.values):\n",
    "        axs.bar(\n",
    "            start, val, width=axs.containers[-1].get_children()[-1].get_width(),\n",
    "            align=\"edge\",\n",
    "            edgecolor=edgecolor or axs.containers[i].get_children()[-1].get_edgecolor(),\n",
    "            linewidth=axs.containers[i].get_children()[-1].get_linewidth(),\n",
    "            color=hue_cmap[i] if hue_cmap else axs.containers[i].get_children()[-1].get_facecolor(),\n",
    "        )\n",
    "        start += axs.containers[-1].get_children()[-1].get_width()\n",
    "#     xt = axs.get_xticks()\n",
    "#     xt = np.append(xt, -1)\n",
    "\n",
    "#     axs.set_xticks(xt)\n",
    "#     xtl = axs.get_xticklabels()\n",
    "#     xtl[-1] = \"Target\"\n",
    "#     axs.set_xticklabels(xtl)\n",
    "\n",
    "\n",
    "def get_labelstr(method, width=10):\n",
    "    try:\n",
    "        label = textwrap.fill(conf.methods[method].label, width)\n",
    "    except:\n",
    "        label = method\n",
    "    return label\n",
    "\n",
    "def set_ax(ax, score_conf, leadtime_limits, leadtime_locator_multiples=[15, 5]):\n",
    "    \"\"\"Set axis limits and ticks.\"\"\"\n",
    "    if score_conf[\"limits\"] is not None:\n",
    "        ax.set_ylim(*score_conf[\"limits\"])\n",
    "    else:\n",
    "        ax.autoscale(enable=True, axis=\"y\", tight=True)\n",
    "    if score_conf[\"ticks\"] and len(score_conf[\"ticks\"]) == 3:\n",
    "        ax.set_yticks(np.arange(*score_conf[\"ticks\"]))\n",
    "    elif score_conf[\"ticks\"] and len(score_conf[\"ticks\"]) == 2:\n",
    "        ax.yaxis.set_major_locator(plt.MultipleLocator(score_conf[\"ticks\"][0]))\n",
    "        ax.yaxis.set_minor_locator(plt.MultipleLocator(score_conf[\"ticks\"][1]))\n",
    "\n",
    "    if score_conf.get(\"log_scale\"):\n",
    "        if score_conf[\"limits\"] is not None:\n",
    "            ax.set_ylim([10 ** score_conf[\"limits\"][0], 10 ** score_conf[\"limits\"][1]])\n",
    "        else:\n",
    "            ax.autoscale(enable=True, axis=\"y\", tight=True)\n",
    "\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.yaxis.set_major_locator(plt.LogLocator(base=10.0, numticks=15))\n",
    "        ax.yaxis.set_minor_locator(plt.NullLocator())\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MultipleLocator(leadtime_locator_multiples[0]))\n",
    "    ax.xaxis.set_minor_locator(plt.MultipleLocator(leadtime_locator_multiples[1]))\n",
    "    \n",
    "    # Add first and last leadtime tick labels\n",
    "    ax.set_xticks(list(ax.get_xticks()) + leadtime_limits)\n",
    "    \n",
    "    ax.set_xlim(*leadtime_limits)\n",
    "    ax.set_xlabel(\"Leadtime [min]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f28cd-1f7c-4ce0-926b-6ffc5b120982",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff31d71-56a9-40d7-96dc-234d308e389b",
   "metadata": {},
   "source": [
    "## Base data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cdf0cb-1dc2-4346-8127-ffa45ff48c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf = \"../config/swiss-data/plot_metrics_objects_review.yaml\"\n",
    "conf = load_yaml_config(conf)\n",
    "\n",
    "COLORS_METHODS = {m: conf.methods[m].color for m in conf.methods}\n",
    "\n",
    "exp_id = conf.exp_id\n",
    "result_dir = conf.path.result_dir.format(id=exp_id)\n",
    "OUTPUT_DIR = Path(conf.path.save_dir.format(id=exp_id)) / \"figs_article\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "metric = \"OBJECTS_ALL\"\n",
    "files = sorted(Path(result_dir).glob(f\"*{metric}*.nc\"))\n",
    "\n",
    "path = files[0]\n",
    "\n",
    "DATASET = xr.open_dataset(path)\n",
    "DATASET = DATASET.drop_duplicates(dim=\"sample\")\n",
    "\n",
    "\n",
    "# Change unit of rr sum to 1e6 m^3/h\n",
    "DATASET[\"prev_sum_rr\"] = DATASET[\"prev_sum_rr\"] * 1e-3\n",
    "DATASET[\"obs_sum_rr\"] = DATASET[\"obs_sum_rr\"] * 1e-3\n",
    "DATASET[\"pred_sum_rr\"] = DATASET[\"pred_sum_rr\"] * 1e-3\n",
    "DATASET[\"sum_rr_diff\"] = DATASET[\"pred_sum_rr\"] - DATASET[\"obs_sum_rr\"]\n",
    "\n",
    "DATASET[\"cell_match_obs_sum_rr\"] = DATASET[\"cell_match_obs_sum_rr\"] * 1e-3\n",
    "DATASET[\"cell_match_pred_sum_rr\"] = DATASET[\"cell_match_pred_sum_rr\"] * 1e-3\n",
    "\n",
    "# Calculate differences\n",
    "DATASET[\"max_rr_diff\"] = DATASET[\"pred_max_rr\"] - DATASET[\"obs_max_rr\"]\n",
    "DATASET[\"mean_rr_diff\"] = DATASET[\"pred_mean_rr\"] - DATASET[\"obs_mean_rr\"]\n",
    "DATASET[\"lifetime_diff\"] = DATASET[\"pred_lifetime\"] - DATASET[\"obs_lifetime\"]\n",
    "DATASET[\"area_diff\"] = DATASET[\"pred_area\"] - DATASET[\"obs_area\"]\n",
    "\n",
    "# Maximum area in track\n",
    "DATASET[\"max_prev_area\"] = DATASET[\"prev_area\"].max(dim=\"prev_time\", skipna=True) \n",
    "DATASET[\"max_obs_area\"] = DATASET[\"obs_area\"].max(dim=\"leadtime\", skipna=True) \n",
    "\n",
    "DATASET[\"max_area\"] = ([\"sample\", \"track\"], np.nanmax([DATASET[\"max_prev_area\"].values, DATASET[\"max_obs_area\"].values], axis=0))\n",
    "\n",
    "# Track lifetime\n",
    "DATASET[\"lifetime_prev\"] = DATASET[\"prev_mean_rr\"].count(dim=\"prev_time\")\n",
    "DATASET[\"lifetime_full\"] = DATASET[\"lifetime_prev\"] + DATASET[\"obs_lifetime\"]\n",
    "\n",
    "# Maximum RVR in track\n",
    "DATASET[\"track_max_prev_rr\"] = DATASET[\"prev_sum_rr\"].max(dim=\"prev_time\", skipna=True)\n",
    "DATASET[\"track_max_obs_rr\"] = DATASET[\"obs_sum_rr\"].max(dim=\"leadtime\", skipna=True)\n",
    "DATASET[\"track_max_pred_rr\"] = DATASET[\"pred_sum_rr\"].max(dim=\"leadtime\", skipna=True)\n",
    "DATASET[\"track_argmax_obs_rr\"] = DATASET[\"obs_sum_rr\"].fillna(-1000).argmax(dim=\"leadtime\", skipna=True).where(\n",
    "    DATASET[\"track_max_obs_rr\"] > 0)\n",
    "\n",
    "# Minimum RVR in track\n",
    "DATASET[\"track_min_prev_rr\"] = DATASET[\"prev_sum_rr\"].min(dim=\"prev_time\", skipna=True)\n",
    "DATASET[\"track_min_obs_rr\"] = DATASET[\"obs_sum_rr\"].min(dim=\"leadtime\", skipna=True)\n",
    "DATASET[\"track_min_pred_rr\"] = DATASET[\"pred_sum_rr\"].min(dim=\"leadtime\", skipna=True)\n",
    "\n",
    "# General variables\n",
    "DATASET = DATASET.where(DATASET.method.isin(conf.legend_order))\n",
    "N_METHODS = np.unique(DATASET.method.values).size\n",
    "METHODS = np.unique(DATASET.method.values)\n",
    "\n",
    "sorter = np.argsort(np.array(conf.legend_order))\n",
    "\n",
    "DATASET_BASE = DATASET.copy()\n",
    "DATASET_BASE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8efc900-880c-43fe-babb-53f648a3823e",
   "metadata": {},
   "source": [
    "## Cell state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa428b8-ed2c-40a3-b962-2926594a3281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_ = DATASET.copy()\n",
    "\n",
    "# State according to derivative definition\n",
    "derivative_at_t0 = xr.concat([\n",
    "    DATASET[\"prev_sum_rr\"].sel(prev_time=[-2, -1, 0]).rename({\"prev_time\": \"leadtime\"}), \n",
    "    DATASET[\"obs_sum_rr\"].sel(leadtime=[1, 2,])\n",
    "], dim=\"leadtime\").differentiate(\"leadtime\").sel(leadtime=0)\n",
    "\n",
    "num_point_in_derivative = xr.concat([\n",
    "    DATASET[\"prev_sum_rr\"].sel(prev_time=[-2, -1, 0]).rename({\"prev_time\": \"leadtime\"}), \n",
    "    DATASET[\"obs_sum_rr\"].sel(leadtime=[1, 2,])\n",
    "], dim=\"leadtime\").count(dim=\"leadtime\")\n",
    "\n",
    "ds_[\"obs_derivative_at_t0\"] = derivative_at_t0\n",
    "ds_[\"num_points_in_obs_derivative\"] = num_point_in_derivative\n",
    "\n",
    "growth_cond = derivative_at_t0 > 0\n",
    "decay_cond = (\n",
    "    ((derivative_at_t0) < 0) | \n",
    "    ((ds_[\"track_max_prev_rr\"] > 0) & (ds_[\"prev_sum_rr\"].sel(prev_time=0) > 0) & (derivative_at_t0.isnull()))\n",
    ")\n",
    "stable_cond = (\n",
    "    (np.abs(derivative_at_t0) == 0)\n",
    "    & ((ds_[\"track_max_prev_rr\"] > 0) & (ds_[\"track_max_obs_rr\"] > 0))\n",
    ")\n",
    "ds_[\"state\"] = xr.ones_like(ds_[\"track_max_prev_rr\"]) * np.nan\n",
    "ds_[\"state\"] = ds_[\"state\"].where(~growth_cond, \"growth\")\n",
    "ds_[\"state\"] = ds_[\"state\"].where(~decay_cond, \"decay\")\n",
    "ds_[\"state\"] = ds_[\"state\"].where(~stable_cond, \"stable\")\n",
    "\n",
    "# As integer for confusion matrix\n",
    "ds_[\"state_int\"] = xr.ones_like(ds_[\"track_max_prev_rr\"]) * np.nan\n",
    "ds_[\"state_int\"] = ds_[\"state_int\"].where(~growth_cond, 1)\n",
    "ds_[\"state_int\"] = ds_[\"state_int\"].where(~decay_cond, 2)\n",
    "ds_[\"state_int\"] = ds_[\"state_int\"].where(~stable_cond, 3)\n",
    "\n",
    "# Predicted state according to derivative definition\n",
    "# Predicted state per track\n",
    "derivative_pred_at_t0 = xr.concat([\n",
    "    DATASET[\"prev_sum_rr\"].sel(prev_time=[-2, -1, 0]).rename({\"prev_time\": \"leadtime\"}), \n",
    "    DATASET[\"pred_sum_rr\"].sel(leadtime=[1, 2,])\n",
    "], dim=\"leadtime\").differentiate(\"leadtime\").sel(leadtime=0)\n",
    "\n",
    "num_point_in_pred_derivative = xr.concat([\n",
    "    DATASET[\"prev_sum_rr\"].sel(prev_time=[-2, -1, 0]).rename({\"prev_time\": \"leadtime\"}), \n",
    "    DATASET[\"pred_sum_rr\"].sel(leadtime=[1, 2,])\n",
    "], dim=\"leadtime\").count(dim=\"leadtime\")\n",
    "\n",
    "ds_[\"pred_derivative_at_t0\"] = derivative_pred_at_t0\n",
    "ds_[\"num_points_in_pred_derivative\"] = num_point_in_pred_derivative\n",
    "growth_cond_pred = derivative_pred_at_t0 > 0\n",
    "decay_cond_pred = (\n",
    "    (derivative_pred_at_t0 < 0) | \n",
    "    ((ds_[\"track_max_prev_rr\"] > 0) &  (ds_[\"prev_sum_rr\"].sel(prev_time=0) > 0) & (derivative_pred_at_t0.isnull()))\n",
    ")\n",
    "stable_cond_pred = (\n",
    "    (np.abs(derivative_pred_at_t0) == 0) & \n",
    "    ((ds_[\"track_max_prev_rr\"] > 0) & (ds_[\"track_max_pred_rr\"] > 0))\n",
    ")\n",
    "\n",
    "ds_[\"state_pred\"] = xr.ones_like(ds_[\"track_max_prev_rr\"]) * np.nan\n",
    "ds_[\"state_pred\"] = ds_[\"state_pred\"].where(~growth_cond_pred, \"growth\")\n",
    "ds_[\"state_pred\"] = ds_[\"state_pred\"].where(~decay_cond_pred, \"decay\")\n",
    "ds_[\"state_pred\"] = ds_[\"state_pred\"].where(~stable_cond_pred, \"stable\")\n",
    "\n",
    "# As integer for confusion matrix\n",
    "ds_[\"state_pred_int\"] = xr.ones_like(ds_[\"track_max_prev_rr\"]) * np.nan\n",
    "ds_[\"state_pred_int\"] = ds_[\"state_pred_int\"].where(~growth_cond_pred, 1)\n",
    "ds_[\"state_pred_int\"] = ds_[\"state_pred_int\"].where(~decay_cond_pred, 2)\n",
    "ds_[\"state_pred_int\"] = ds_[\"state_pred_int\"].where(~stable_cond_pred, 3)\n",
    "\n",
    "DATASET_CELL_STATE = ds_.copy()\n",
    "\n",
    "DATASET_CELL_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e2d599-2585-4f7b-ba8c-8ef2dba6d7e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_leadtimes = DATASET_BASE.leadtime.values.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5adcf4-11db-453f-9393-5f036a804f6c",
   "metadata": {},
   "source": [
    "# Number of splits and merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d3f3f7-6e22-42c5-9bb9-a662b0310eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_obs = DATASET[[\"obs_merged\", \"obs_from_split\"]].sum(dim=[\"track\", \"sample\"]).to_dataframe().reset_index()\n",
    "ds_pred = DATASET[[\"pred_merged\", \"pred_from_split\"]].sum(dim=[\"track\", \"sample\"]).to_dataframe().reset_index()\n",
    "\n",
    "track_exists_cond = (DATASET[\"track_max_prev_rr\"] > 0) & ((DATASET[\"prev_sum_rr\"].sel(prev_time=0) > 0))\n",
    "\n",
    "ds_obs_count = (DATASET[\"obs_area\"] > 0).sum(dim=[\"track\", \"sample\"]).to_dataframe(name=\"obs_total_count\").reset_index()\n",
    "ds_pred_count = (DATASET[\"pred_area\"] > 0).sum(dim=[\"track\", \"sample\"]).to_dataframe(name=\"pred_total_count\").reset_index()\n",
    "\n",
    "ds_obs_split_or_merge = ((DATASET[\"obs_merged\"].fillna(0) + DATASET[\"obs_from_split\"].fillna(0)) > 0).sum(dim=[\"track\", \"sample\"]).to_dataframe(name=\"obs_split_or_merge\").reset_index()\n",
    "ds_pred_split_or_merge = ((DATASET[\"pred_merged\"].fillna(0) + DATASET[\"pred_from_split\"].fillna(0)) > 0).sum(dim=[\"track\", \"sample\"]).to_dataframe(name=\"pred_split_or_merge\").reset_index()\n",
    "\n",
    "ds_obs_split_and_merge = ((DATASET[\"obs_merged\"].fillna(0) + DATASET[\"obs_from_split\"].fillna(0)) > 1).sum(dim=[\"track\", \"sample\"]).to_dataframe(name=\"obs_split_and_merge\").reset_index()\n",
    "ds_pred_split_and_merge = ((DATASET[\"pred_merged\"].fillna(0) + DATASET[\"pred_from_split\"].fillna(0)) > 1).sum(dim=[\"track\", \"sample\"]).to_dataframe(name=\"pred_split_and_merge\").reset_index()\n",
    "\n",
    "df = ds_obs.merge(ds_pred).merge(ds_obs_split_or_merge).merge(ds_pred_split_or_merge).merge(ds_obs_split_and_merge).merge(ds_pred_split_and_merge).merge(ds_obs_count).merge(ds_pred_count)\n",
    "\n",
    "# Define number of only merges and only splits\n",
    "df[\"obs_only_merge\"] = df[\"obs_merged\"] - df[\"obs_split_and_merge\"]\n",
    "df[\"pred_only_merge\"] = df[\"pred_merged\"] - df[\"pred_split_and_merge\"]\n",
    "\n",
    "df[\"obs_only_split\"] = df[\"obs_from_split\"] - df[\"obs_split_and_merge\"]\n",
    "df[\"pred_only_split\"] = df[\"pred_from_split\"] - df[\"pred_split_and_merge\"]\n",
    "\n",
    "# This plotted with colors: cells with no merge or split\n",
    "df[\"obs_plot_no_merge_split\"] = df[\"obs_total_count\"] - df[\"obs_split_or_merge\"]\n",
    "df[\"pred_plot_no_merge_split\"] = df[\"pred_total_count\"] - df[\"pred_split_or_merge\"]\n",
    "\n",
    "# Plotted on top with gray: cells with only splits\n",
    "df[\"obs_plot_only_split\"] = df[\"obs_only_split\"] + df[\"obs_plot_no_merge_split\"]\n",
    "df[\"pred_plot_only_split\"] = df[\"pred_only_split\"] + df[\"pred_plot_no_merge_split\"]\n",
    "\n",
    "# Plotted on top with white: cells with only merges\n",
    "df[\"obs_plot_only_merge\"] = df[\"obs_only_merge\"] + df[\"obs_plot_only_split\"]\n",
    "df[\"pred_plot_only_merge\"] = df[\"pred_only_merge\"] + df[\"pred_plot_only_split\"]\n",
    "\n",
    "# Plotted last with black: cells with both merges and splits\n",
    "df[\"obs_plot_both_merge_split\"] = df[\"obs_split_and_merge\"] + df[\"obs_plot_only_merge\"]\n",
    "df[\"pred_plot_both_merge_split\"] = df[\"pred_split_and_merge\"] + df[\"pred_plot_only_merge\"]\n",
    "\n",
    "\n",
    "# Contingency table for metrics\n",
    "\n",
    "cell_merge_nowcast = DATASET[\"pred_merged\"] == True\n",
    "cell_merge_obs = DATASET[\"obs_merged\"] == True\n",
    "\n",
    "cell_merge_nowcast = cell_merge_nowcast.where(track_exists_cond, 2)\n",
    "cell_merge_obs = cell_merge_obs.where(track_exists_cond, 2)\n",
    "\n",
    "contingency_merge = xs.Contingency(\n",
    "    cell_merge_obs, \n",
    "    cell_merge_nowcast, \n",
    "    np.array([0, 0.5, 1.0]), \n",
    "    np.array([0, 0.5, 1.0]), \n",
    "    dim=[\"sample\", \"track\"],\n",
    ")\n",
    "contingency_merge.table\n",
    "\n",
    "cell_split_nowcast = DATASET[\"pred_from_split\"] == True\n",
    "cell_split_obs = DATASET[\"obs_from_split\"] == True\n",
    "\n",
    "cell_split_nowcast = cell_split_nowcast.where(track_exists_cond, 2)\n",
    "cell_split_obs = cell_split_obs.where(track_exists_cond, 2)\n",
    "\n",
    "contingency_split = xs.Contingency(\n",
    "    cell_split_obs, \n",
    "    cell_split_nowcast, \n",
    "    np.array([0, 0.5, 1.0]), \n",
    "    np.array([0, 0.5, 1.0]), \n",
    "    dim=[\"sample\", \"track\"],\n",
    ")\n",
    "contingency_split.table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357e89e-86f9-432b-951e-7d6257883f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[[\"method\", \"leadtime\", \"obs_merged\", \"obs_from_split\", \"obs_split_and_merge\", \"obs_split_or_merge\", \"obs_total_count\", \"pred_total_count\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d178c-7b21-4488-ae1d-00ecdd5a25db",
   "metadata": {},
   "source": [
    "## Figure in absolute numbers with contingency metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776c67b-75c7-49e8-8091-b071345bd292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(layout=\"constrained\", figsize=(12, 12))\n",
    "\n",
    "axs = fig.subplot_mosaic([\n",
    "        [\".\", \"counts\", \"counts\", \"counts\", \"counts\", \".\"],\n",
    "        [\"CSI_merge\", \"CSI_merge\", \"POD_merge\",\"POD_merge\", \"FAR_merge\",\"FAR_merge\"],\n",
    "        [\"CSI_split\", \"CSI_split\", \"POD_split\",\"POD_split\", \"FAR_split\",\"FAR_split\"],\n",
    "    ], \n",
    "    width_ratios=[0.2, 0.1, 0.15, 0.15, 0.1, 0.2],\n",
    "    height_ratios=[0.5, 0.5, 0.5],\n",
    "    # gridspec_kw={'wspace': 0.0, \"w_pad\": 0}\n",
    ")\n",
    "\n",
    "df.sort_values(\n",
    "    by=[\"method\", \"leadtime\"],\n",
    "    key=lambda x: sorter[\n",
    "        np.searchsorted(np.array(conf.legend_order), x, sorter=sorter)\n",
    "    ] if isinstance(x.values[0], str) else x,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "g_both_split_merge = sns.barplot(\n",
    "    ax=axs[\"counts\"], \n",
    "    data=df, \n",
    "    x=\"method\", \n",
    "    hue=\"leadtime\", \n",
    "    y=\"pred_plot_both_merge_split\", \n",
    "    palette=[\"k\"]*n_leadtimes, \n",
    "    edgecolor=\"black\", \n",
    "    linewidth=0.5, \n",
    "    legend=False,\n",
    ")\n",
    "# Plot target counts\n",
    "plot_obs_counts(df.loc[df.method==\"extrapolation\"][\"obs_plot_both_merge_split\"], axs[\"counts\"], hue_cmap=[\"k\"]*n_leadtimes, edgecolor=\"black\")\n",
    "\n",
    "\n",
    "g_obs_total_count = sns.barplot(\n",
    "    ax=axs[\"counts\"], \n",
    "    data=df, \n",
    "    x=\"method\", \n",
    "    y=\"pred_plot_only_merge\", \n",
    "    hue=\"leadtime\", \n",
    "    palette=[\"w\"]*n_leadtimes, \n",
    "    edgecolor=\"black\", \n",
    "    linewidth=0.5, \n",
    "    legend=False,\n",
    ")\n",
    "# Plot target counts\n",
    "plot_obs_counts(df.loc[df.method==\"extrapolation\"][\"obs_plot_only_merge\"], axs[\"counts\"], hue_cmap=[\"w\"]*n_leadtimes, edgecolor=\"black\")\n",
    "\n",
    "# Merged and split cells\n",
    "g_pred_merged_split = sns.barplot(\n",
    "    ax=axs[\"counts\"], \n",
    "    data=df, \n",
    "    x=\"method\", \n",
    "    hue=\"leadtime\", \n",
    "    y=\"pred_plot_only_split\", \n",
    "    palette=[\"tab:gray\"]*n_leadtimes, \n",
    "    edgecolor=\"black\", \n",
    "    linewidth=0.5, \n",
    "    legend=False,\n",
    ")\n",
    "# Plot target counts\n",
    "plot_obs_counts(df.loc[df.method==\"extrapolation\"][\"obs_plot_only_split\"], axs[\"counts\"], hue_cmap=[\"tab:gray\"]*n_leadtimes, edgecolor=\"black\")\n",
    "    \n",
    "g_pred_merged = sns.barplot(\n",
    "    ax=axs[\"counts\"], \n",
    "    data=df, \n",
    "    x=\"method\", \n",
    "    y=\"pred_plot_no_merge_split\",\n",
    "    hue=\"leadtime\", \n",
    "    palette=HUE_CMAP, \n",
    "    edgecolor=\"black\", \n",
    "    linewidth=0.5, \n",
    "    legend=\"full\"\n",
    ")\n",
    "g_pred_merged.axes.get_legend().remove()\n",
    "# Plot target counts\n",
    "plot_obs_counts(df.loc[df.method==\"extrapolation\"][\"obs_plot_no_merge_split\"], axs[\"counts\"], hue_cmap=sns.color_palette(HUE_CMAP, n_colors=n_leadtimes), edgecolor=\"black\")\n",
    "\n",
    "axs[\"counts\"].set_title(f\"(a) Cell counts\")\n",
    "axs[\"counts\"].set_xticklabels([get_labelstr(l.get_text()) for l in axs[\"counts\"].get_xticklabels()])\n",
    "axs[\"counts\"].set_autoscale_on(False)\n",
    "axs[\"counts\"].set_ylim(0, 225e3)\n",
    "axs[\"counts\"].set_ylabel(COUNT_TITLE)\n",
    "# ax.set_ylim(LIFETIME_LIMITS)\n",
    "# ax.yaxis.set_major_locator(ticker.MultipleLocator(LIFETIME_TICK_MULTIPLE))\n",
    "axs[\"counts\"].yaxis.set_major_locator(ticker.MultipleLocator(25e3))\n",
    "axs[\"counts\"].yaxis.set_minor_locator(ticker.MultipleLocator(5e3))\n",
    "axs[\"counts\"].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f\"{x / 1000:.0f}\"))\n",
    "axs[\"counts\"].grid(which=\"major\", axis=\"y\")\n",
    "axs[\"counts\"].grid(which=\"minor\", axis=\"y\", alpha=0.2)\n",
    "axs[\"counts\"].set_autoscale_on(False)\n",
    "axs[\"counts\"].set_xlabel(METHOD_X_LABEL)\n",
    "\n",
    "h, l = axs[\"counts\"].get_legend_handles_labels()\n",
    "l1 = fig.legend(\n",
    "    h,\n",
    "    [leadtime_to_minutes((int(s)), 0) for s in l],\n",
    "    title=\"Leadtime [min]\",\n",
    "    bbox_to_anchor=(0.8, 0.8),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=1,\n",
    ")\n",
    "fig.add_artist(l1)\n",
    "\n",
    "# Make legend for hits, misses, false alarms, correct negatives labels\n",
    "palette_hue = sns.color_palette(HUE_CMAP, n_leadtimes)\n",
    "hits_patch = [patches.Patch(facecolor=c, edgecolor=c, label=\"No split or merge\") for c in palette_hue]\n",
    "\n",
    "split_patch = patches.Patch(facecolor=\"tab:gray\", edgecolor=\"tab:gray\", label=\"Split\")\n",
    "merge_patch = patches.Patch(facecolor=\"white\", edgecolor=\"k\", label=\"Merge\")\n",
    "both_split_merge_patch = patches.Patch(facecolor=\"k\", edgecolor=\"tab:gray\", label=\"Both split and merge\")\n",
    "\n",
    "other_patches = [split_patch, merge_patch, both_split_merge_patch]\n",
    "\n",
    "leg = fig.legend(\n",
    "    handles=[hits_patch, *other_patches], \n",
    "    labels=[\"No split or merge\", *[p.get_label() for p in other_patches]], \n",
    "    handler_map={list: HandlerTuple(ndivide=None, pad=0)},\n",
    "    ncols=1,\n",
    "    bbox_to_anchor=(0.8, 0.95),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    ")\n",
    "\n",
    "metrics = [\"CSI\", \"POD\", \"FAR\"]\n",
    "\n",
    "dfs_merge = {\n",
    "    \"CSI\": contingency_merge.threat_score(),\n",
    "    \"POD\": contingency_merge.hit_rate(),\n",
    "    \"FAR\": contingency_merge.false_alarm_ratio(),\n",
    "}\n",
    "dfs_split = {\n",
    "    \"CSI\": contingency_split.threat_score(),\n",
    "    \"POD\": contingency_split.hit_rate(),\n",
    "    \"FAR\": contingency_split.false_alarm_ratio(),\n",
    "}\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    df_ = dfs_merge[metric]\n",
    "    # Change leadtime to minutes\n",
    "    df_[\"leadtime\"] = df_[\"leadtime\"] * 5\n",
    "    for model in conf.legend_order:\n",
    "        df_.sel(dict(method=model)).plot.line(\n",
    "            ax=axs[f\"{metric}_merge\"],\n",
    "            x=\"leadtime\",\n",
    "            color=conf.methods[model][\"color\"],\n",
    "            label=conf.methods[model][\"label\"],\n",
    "            linestyle=conf.methods[model][\"linestyle\"],\n",
    "        )\n",
    "    set_ax(axs[f\"{metric}_merge\"], conf.metric_conf[metric], [5, 60], conf.leadtime_locator_multiples)\n",
    "    axs[f\"{metric}_merge\"].set_ylabel(conf.metric_conf[metric][\"label\"])\n",
    "    axs[f\"{metric}_merge\"].set_title(f'({alphabet[1+i]}) Merges: {conf.metric_conf[metric][\"full_name\"]}', color=plt.rcParams[\"axes.titlecolor\"])\n",
    "    axs[f\"{metric}_merge\"].grid(which=\"both\", axis=\"both\")\n",
    "    axs[f\"{metric}_merge\"].legend()\n",
    "    \n",
    "    df_ = dfs_split[metric]\n",
    "    # Change leadtime to minutes\n",
    "    df_[\"leadtime\"] = df_[\"leadtime\"] * 5\n",
    "    for model in conf.legend_order:\n",
    "        df_.sel(dict(method=model)).plot.line(\n",
    "            ax=axs[f\"{metric}_split\"],\n",
    "            x=\"leadtime\",\n",
    "            color=conf.methods[model][\"color\"],\n",
    "            label=conf.methods[model][\"label\"],\n",
    "            linestyle=conf.methods[model][\"linestyle\"],\n",
    "        )\n",
    "    set_ax(axs[f\"{metric}_split\"], conf.metric_conf[metric], [5, 60], conf.leadtime_locator_multiples)\n",
    "    axs[f\"{metric}_split\"].set_ylabel(conf.metric_conf[metric][\"label\"])\n",
    "    axs[f\"{metric}_split\"].set_title(f'({alphabet[1 + len(metrics) + i]}) Splits: {conf.metric_conf[metric][\"full_name\"]}', color=plt.rcParams[\"axes.titlecolor\"])\n",
    "    axs[f\"{metric}_split\"].grid(which=\"both\", axis=\"both\")\n",
    "    axs[f\"{metric}_split\"].legend()\n",
    "\n",
    "\n",
    "outputname = \"split_merge_contingency\"\n",
    "save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37437eb5-f677-4542-85c5-6fe4f9d0879d",
   "metadata": {},
   "source": [
    "## Figure in fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6373b8b0-580e-4997-8a9b-ecb4f9031e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(layout=\"constrained\", figsize=(12, 5))\n",
    "\n",
    "axs = fig.subplot_mosaic([\n",
    "        [\"counts\", \".\"],\n",
    "    ], \n",
    "    width_ratios=[0.8, 0.2],\n",
    "    # height_ratios=[0.5, 0.5, 0.5],\n",
    "    # gridspec_kw={'wspace': 0.0, \"w_pad\": 0}\n",
    ")\n",
    "\n",
    "df_pct = df.copy()\n",
    "df_pct[\"pred_plot_only_merge\"] /= df_pct[\"pred_plot_both_merge_split\"]\n",
    "df_pct[\"pred_plot_only_split\"] /= df_pct[\"pred_plot_both_merge_split\"]\n",
    "df_pct[\"pred_plot_no_merge_split\"] /= df_pct[\"pred_plot_both_merge_split\"]\n",
    "df_pct[\"pred_plot_both_merge_split\"] /= df_pct[\"pred_plot_both_merge_split\"]\n",
    "\n",
    "df_pct[\"obs_plot_only_merge\"] /= df_pct[\"obs_plot_both_merge_split\"]\n",
    "df_pct[\"obs_plot_only_split\"] /= df_pct[\"obs_plot_both_merge_split\"]\n",
    "df_pct[\"obs_plot_no_merge_split\"] /= df_pct[\"obs_plot_both_merge_split\"]\n",
    "df_pct[\"obs_plot_both_merge_split\"] /= df_pct[\"obs_plot_both_merge_split\"]\n",
    "\n",
    "\n",
    "df_pct.sort_values(\n",
    "    by=[\"method\", \"leadtime\"],\n",
    "    key=lambda x: sorter[\n",
    "        np.searchsorted(np.array(conf.legend_order), df.method.values, sorter=sorter)\n",
    "    ] if isinstance(x.values[0], str) else x,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "g_both_split_merge = sns.barplot(\n",
    "    ax=axs[\"counts\"], \n",
    "    data=df_pct, \n",
    "    x=\"method\", \n",
    "    hue=\"leadtime\", \n",
    "    y=\"pred_plot_both_merge_split\", \n",
    "    palette=[\"k\"]*n_leadtimes, \n",
    "    edgecolor=\"black\", \n",
    "    linewidth=0.5, \n",
    "    legend=False,\n",
    ")\n",
    "# Plot target counts\n",
    "plot_obs_counts(df_pct.loc[df_pct.method==\"extrapolation\"][\"obs_plot_both_merge_split\"], axs[\"counts\"], hue_cmap=[\"k\"]*n_leadtimes, edgecolor=\"black\")\n",
    "\n",
    "\n",
    "g_obs_total_count = sns.barplot(\n",
    "    ax=axs[\"counts\"], \n",
    "    data=df_pct, \n",
    "    x=\"method\", \n",
    "    y=\"pred_plot_only_merge\", \n",
    "    hue=\"leadtime\", \n",
    "    palette=[\"w\"]*n_leadtimes, \n",
    "    edgecolor=\"black\", \n",
    "    linewidth=0.5, \n",
    "    legend=False,\n",
    ")\n",
    "# Plot target counts\n",
    "plot_obs_counts(df_pct.loc[df_pct.method==\"extrapolation\"][\"obs_plot_only_merge\"], axs[\"counts\"], hue_cmap=[\"w\"]*n_leadtimes, edgecolor=\"black\")\n",
    "\n",
    "# Merged and split cells\n",
    "g_pred_merged_split = sns.barplot(\n",
    "    ax=axs[\"counts\"], \n",
    "    data=df_pct, \n",
    "    x=\"method\", \n",
    "    hue=\"leadtime\", \n",
    "    y=\"pred_plot_only_split\", \n",
    "    palette=[\"tab:gray\"]*n_leadtimes, \n",
    "    edgecolor=\"black\", \n",
    "    linewidth=0.5, \n",
    "    legend=False,\n",
    ")\n",
    "# Plot target counts\n",
    "plot_obs_counts(df_pct.loc[df_pct.method==\"extrapolation\"][\"obs_plot_only_split\"], axs[\"counts\"], hue_cmap=[\"tab:gray\"]*n_leadtimes, edgecolor=\"black\")\n",
    "    \n",
    "g_pred_merged = sns.barplot(\n",
    "    ax=axs[\"counts\"], \n",
    "    data=df_pct, \n",
    "    x=\"method\", \n",
    "    y=\"pred_plot_no_merge_split\",\n",
    "    hue=\"leadtime\", \n",
    "    palette=HUE_CMAP, \n",
    "    edgecolor=\"black\", \n",
    "    linewidth=0.5, \n",
    "    legend=\"full\",\n",
    "    zorder=1,\n",
    ")\n",
    "g_pred_merged.axes.get_legend().remove()\n",
    "# Plot target counts\n",
    "plot_obs_counts(df_pct.loc[df_pct.method==\"extrapolation\"][\"obs_plot_no_merge_split\"], axs[\"counts\"], hue_cmap=sns.color_palette(HUE_CMAP, n_colors=n_leadtimes), edgecolor=\"black\")\n",
    "\n",
    "# axs[\"counts\"].set_title(f\"(a) Cell counts\")\n",
    "axs[\"counts\"].set_xticklabels([get_labelstr(l.get_text()) for l in axs[\"counts\"].get_xticklabels()])\n",
    "axs[\"counts\"].set_autoscale_on(False)\n",
    "axs[\"counts\"].set_ylim(0, 1)\n",
    "# axs[\"counts\"].set_ylabel(COUNT_TITLE)\n",
    "axs[\"counts\"].set_ylabel(\"Fraction of cells\")\n",
    "# ax.set_ylim(LIFETIME_LIMITS)\n",
    "# ax.yaxis.set_major_locator(ticker.MultipleLocator(LIFETIME_TICK_MULTIPLE))\n",
    "axs[\"counts\"].yaxis.set_major_locator(ticker.MultipleLocator(0.1))\n",
    "axs[\"counts\"].yaxis.set_minor_locator(ticker.MultipleLocator(0.025))\n",
    "# axs[\"counts\"].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f\"{x / 1000:.0f}\"))\n",
    "axs[\"counts\"].grid(which=\"major\", axis=\"y\", zorder=10)\n",
    "axs[\"counts\"].grid(which=\"minor\", axis=\"y\", alpha=0.2, zorder=10)\n",
    "axs[\"counts\"].set_autoscale_on(False)\n",
    "axs[\"counts\"].set_xlabel(METHOD_X_LABEL)\n",
    "\n",
    "h, l = axs[\"counts\"].get_legend_handles_labels()\n",
    "l1 = fig.legend(\n",
    "    h,\n",
    "    [leadtime_to_minutes((int(s)), 0) for s in l],\n",
    "    title=\"Leadtime [min]\",\n",
    "    bbox_to_anchor=(0.83, 0.4),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=1,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "fig.add_artist(l1)\n",
    "\n",
    "# Make legend for hits, misses, false alarms, correct negatives labels\n",
    "palette_hue = sns.color_palette(HUE_CMAP, n_leadtimes)\n",
    "hits_patch = [patches.Patch(facecolor=c, edgecolor=c, label=\"No split or merge\") for c in palette_hue]\n",
    "\n",
    "split_patch = patches.Patch(facecolor=\"tab:gray\", edgecolor=\"tab:gray\", label=\"Split\")\n",
    "merge_patch = patches.Patch(facecolor=\"white\", edgecolor=\"k\", label=\"Merge\")\n",
    "both_split_merge_patch = patches.Patch(facecolor=\"k\", edgecolor=\"tab:gray\", label=\"Both split and merge\")\n",
    "\n",
    "other_patches = [split_patch, merge_patch, both_split_merge_patch]\n",
    "\n",
    "leg = fig.legend(\n",
    "    handles=[hits_patch, *other_patches], \n",
    "    labels=[\"No split or merge\", *[p.get_label() for p in other_patches]], \n",
    "    handler_map={list: HandlerTuple(ndivide=None, pad=0)},\n",
    "    ncols=1,\n",
    "    bbox_to_anchor=(0.83, 0.85),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "\n",
    "# Set target ticklabels\n",
    "xt = axs[\"counts\"].get_xticks()\n",
    "xt = np.append(xt, -1)\n",
    "\n",
    "axs[\"counts\"].set_xticks(xt)\n",
    "xtl = axs[\"counts\"].get_xticklabels()\n",
    "xtl[-1] = \"Target\"\n",
    "axs[\"counts\"].set_xticklabels(xtl)\n",
    "\n",
    "outputname = \"split_merge_counts\"\n",
    "df_pct.to_csv(f\"{OUTPUT_DIR}/{outputname}.csv\")\n",
    "save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
