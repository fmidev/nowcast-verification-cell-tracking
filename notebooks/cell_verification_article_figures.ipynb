{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for the manuscript \"Cell-based estimation of nowcast model skill for reproducing growth and decay of convective rainfall\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pysteps.visualization.spectral import plot_spectrum1d\n",
    "import geopandas as gpd\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib import colors, cm, gridspec, ticker, patches\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from copy import copy\n",
    "import cmcrameri  # noqa\n",
    "import palettable  # noqa\n",
    "import textwrap\n",
    "import string\n",
    "import pandas as pd\n",
    "import xskillscore as xs\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "from flox.xarray import xarray_reduce\n",
    "from collections import defaultdict\n",
    "\n",
    "alphabet = string.ascii_lowercase\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General definitions for style etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MEDIANPROPS = dict(linestyle=\"-\", linewidth=2, color=\"k\")\n",
    "MEANLINEPROPS = dict(linestyle=(0, (1,0.4)), linewidth=2, color=\"k\")\n",
    "FLIERPROPS = dict(marker=\"o\", markersize=0.3, markerfacecolor=\"gray\", markeredgecolor=\"gray\", rasterized=True)\n",
    "ZEROLINE_PROPS = dict(linestyle=\"--\", linewidth=1.5, color=\"gray\")\n",
    "\n",
    "\n",
    "STATE_GROUP_TITLES = {\n",
    "    \"growth\": \"Growing cells\",\n",
    "    \"decay\": \"Decaying cells\",\n",
    "    \"all\": \"All cells\",\n",
    "}\n",
    "\n",
    "HUE_CMAP = \"cmc.hawaii_r\"\n",
    "\n",
    "PLOT_EXT = \"png\"\n",
    "\n",
    "MAX_RR_LIMITS = (-125, 125)\n",
    "MEAN_RR_LIMITS = (-20, 20)\n",
    "SUM_RR_LIMITS = (-10, 20)\n",
    "LIFETIME_LIMITS = (-12, 12)\n",
    "AREA_LIMITS = (-600, 1000)\n",
    "COUNT_LIMITS = (0, 20000)\n",
    "CENTROID_DISTANCE_LIMITS = (0, 30)\n",
    "\n",
    "MAX_RR_TICK_MULTIPLE = 25\n",
    "MEAN_RR_TICK_MULTIPLE = 5\n",
    "SUM_RR_TICK_MULTIPLE = 5\n",
    "LIFETIME_TICK_MULTIPLE = 2\n",
    "AREA_TICK_MULTIPLE = 200\n",
    "COUNT_TICK_MULTIPLE = 1000\n",
    "\n",
    "MAX_RR_DIFF_TITLE = \"Difference in maximum rainfall rate [mm h$^{-1}$]\"\n",
    "MEAN_RR_DIFF_TITLE = \"Difference in mean rainfall rate [mm h$^{-1}$]\"\n",
    "SUM_RR_DIFF_TITLE = \"Difference in volume rain rate [10$^6$ m$^3$h$^{-1}$]\"\n",
    "LIFETIME_TITLE = \"Difference in lifetime [min]\"\n",
    "AREA_TITLE = \"Difference in area [km$^2$]\"\n",
    "COUNT_TITLE = \"Cell count [10$^3$]\"\n",
    "CENTROID_DISTANCE_TITLE = \"Centroid distance [km]\"\n",
    "\n",
    "METHOD_X_LABEL = \"Model\"\n",
    "\n",
    "W_PER_METHOD_LT = 1.2\n",
    "W_PER_METHOD_S = 0.8\n",
    "\n",
    "FIG_HEIGHT = 6\n",
    "FIG_WIDTH = 6\n",
    "\n",
    "HIST_FIG_H = 2.5\n",
    "HIST_FIG_W = 3\n",
    "\n",
    "# Cut away saturated values\n",
    "MAX_RR_LIMIT = 122\n",
    "\n",
    "# tolerance for zero difference for volume rain rate\n",
    "SUM_RR_ZERO_TOL = 0.0\n",
    "\n",
    "def leadtime_to_minutes(x, pos):\n",
    "    return f\"{x * 5:.0f}\"\n",
    "\n",
    "# Load stylefile\n",
    "plt.style.use(\n",
    "    \"../config/stylefiles/object_figs_article.mplstyle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from addict import Dict\n",
    "import yaml\n",
    "\n",
    "\n",
    "def load_yaml_config(path: str):\n",
    "    \"\"\"\n",
    "    Load a YAML config file as an attribute-dictionnary.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the YAML config file.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Configuration loaded.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        config = Dict(yaml.safe_load(f))\n",
    "    return config\n",
    "\n",
    "\n",
    "def save_figs(fig, outpath, name, extensions, subfolder=None):\n",
    "    if subfolder:\n",
    "        outpath = outpath / subfolder\n",
    "        outpath.mkdir(parents=True, exist_ok=True)\n",
    "    for ext in extensions:\n",
    "        fig.savefig(outpath / f\"{name}.{ext}\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    del fig\n",
    "\n",
    "\n",
    "def create_fig_leadtime_groups(ngroups, nmethods):\n",
    "    return plt.subplots(\n",
    "        ncols=ngroups,\n",
    "        nrows=1,\n",
    "        # figsize=(W_PER_METHOD_S * N_METHODS, FIG_HEIGHT * len(groups)),\n",
    "        figsize=(FIG_WIDTH * ngroups, FIG_HEIGHT),\n",
    "        constrained_layout=True,\n",
    "        sharey=True,\n",
    "        squeeze=True\n",
    "    )\n",
    "\n",
    "def create_fig_hist(ngroups):\n",
    "    return plt.subplots(\n",
    "        ncols=ngroups,\n",
    "        nrows=1,\n",
    "        figsize=(HIST_FIG_W*ngroups, HIST_FIG_H),\n",
    "        constrained_layout=True,\n",
    "        sharey=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_obs_counts(obs_counts, axs):\n",
    "    start = axs.containers[0].get_children()[0].xy[0] - 1\n",
    "    for i, val in enumerate(obs_counts.values):\n",
    "        axs.bar(\n",
    "            start, val, width=axs.containers[-1].get_children()[-1].get_width(),\n",
    "            align=\"edge\",\n",
    "            edgecolor=axs.containers[i].get_children()[-1].get_edgecolor(),\n",
    "            linewidth=axs.containers[i].get_children()[-1].get_linewidth(),\n",
    "            color=axs.containers[i].get_children()[-1].get_facecolor(),\n",
    "        )\n",
    "        start += axs.containers[-1].get_children()[-1].get_width()\n",
    "    xt = axs.get_xticks()\n",
    "    xt = np.append(xt, -1)\n",
    "\n",
    "    axs.set_xticks(xt)\n",
    "    xtl = axs.get_xticklabels()\n",
    "    xtl[-1] = \"Target\"\n",
    "    axs.set_xticklabels(xtl)\n",
    "\n",
    "\n",
    "def get_labelstr(method, width=10):\n",
    "    try:\n",
    "        label = textwrap.fill(conf.methods[method].label, width)\n",
    "    except:\n",
    "        label = method\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_ax(ax, score_conf, leadtime_limits, leadtime_locator_multiples=[15, 5]):\n",
    "    \"\"\"Set axis limits and ticks.\"\"\"\n",
    "    if score_conf[\"limits\"] is not None:\n",
    "        ax.set_ylim(*score_conf[\"limits\"])\n",
    "    else:\n",
    "        ax.autoscale(enable=True, axis=\"y\", tight=True)\n",
    "    if score_conf[\"ticks\"] and len(score_conf[\"ticks\"]) == 3:\n",
    "        ax.set_yticks(np.arange(*score_conf[\"ticks\"]))\n",
    "    elif score_conf[\"ticks\"] and len(score_conf[\"ticks\"]) == 2:\n",
    "        ax.yaxis.set_major_locator(plt.MultipleLocator(score_conf[\"ticks\"][0]))\n",
    "        ax.yaxis.set_minor_locator(plt.MultipleLocator(score_conf[\"ticks\"][1]))\n",
    "\n",
    "    if score_conf.get(\"log_scale\"):\n",
    "        if score_conf[\"limits\"] is not None:\n",
    "            ax.set_ylim([10 ** score_conf[\"limits\"][0], 10 ** score_conf[\"limits\"][1]])\n",
    "        else:\n",
    "            ax.autoscale(enable=True, axis=\"y\", tight=True)\n",
    "\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.yaxis.set_major_locator(plt.LogLocator(base=10.0, numticks=15))\n",
    "        ax.yaxis.set_minor_locator(plt.NullLocator())\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MultipleLocator(leadtime_locator_multiples[0]))\n",
    "    ax.xaxis.set_minor_locator(plt.MultipleLocator(leadtime_locator_multiples[1]))\n",
    "    \n",
    "    # Add first and last leadtime tick labels\n",
    "    ax.set_xticks(list(ax.get_xticks()) + leadtime_limits)\n",
    "    \n",
    "    ax.set_xlim(*leadtime_limits)\n",
    "    ax.set_xlabel(\"Leadtime [min]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read verification configuration file and setup data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Base data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf = \"../config/swiss-data/plot_metrics_objects_review.yaml\"\n",
    "conf = load_yaml_config(conf)\n",
    "\n",
    "COLORS_METHODS = {m: conf.methods[m].color for m in conf.methods}\n",
    "\n",
    "exp_id = conf.exp_id\n",
    "result_dir = conf.path.result_dir.format(id=exp_id)\n",
    "OUTPUT_DIR = Path(conf.path.save_dir.format(id=exp_id)) / \"figs_article\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "metric = \"OBJECTS_ALL\"\n",
    "files = sorted(Path(result_dir).glob(f\"*{metric}*.nc\"))\n",
    "\n",
    "path = files[0]\n",
    "\n",
    "DATASET = xr.open_dataset(path)\n",
    "DATASET = DATASET.drop_duplicates(dim=\"sample\")\n",
    "\n",
    "\n",
    "# Change unit of rr sum to 1e6 m^3/h\n",
    "DATASET[\"prev_sum_rr\"] = DATASET[\"prev_sum_rr\"] * 1e-3\n",
    "DATASET[\"obs_sum_rr\"] = DATASET[\"obs_sum_rr\"] * 1e-3\n",
    "DATASET[\"pred_sum_rr\"] = DATASET[\"pred_sum_rr\"] * 1e-3\n",
    "DATASET[\"sum_rr_diff\"] = DATASET[\"pred_sum_rr\"] - DATASET[\"obs_sum_rr\"]\n",
    "\n",
    "DATASET[\"cell_match_obs_sum_rr\"] = DATASET[\"cell_match_obs_sum_rr\"] * 1e-3\n",
    "DATASET[\"cell_match_pred_sum_rr\"] = DATASET[\"cell_match_pred_sum_rr\"] * 1e-3\n",
    "\n",
    "# Calculate differences\n",
    "DATASET[\"max_rr_diff\"] = DATASET[\"pred_max_rr\"] - DATASET[\"obs_max_rr\"]\n",
    "DATASET[\"mean_rr_diff\"] = DATASET[\"pred_mean_rr\"] - DATASET[\"obs_mean_rr\"]\n",
    "DATASET[\"lifetime_diff\"] = DATASET[\"pred_lifetime\"] - DATASET[\"obs_lifetime\"]\n",
    "DATASET[\"area_diff\"] = DATASET[\"pred_area\"] - DATASET[\"obs_area\"]\n",
    "\n",
    "# Maximum area in track\n",
    "DATASET[\"max_prev_area\"] = DATASET[\"prev_area\"].max(dim=\"prev_time\", skipna=True) \n",
    "DATASET[\"max_obs_area\"] = DATASET[\"obs_area\"].max(dim=\"leadtime\", skipna=True) \n",
    "\n",
    "DATASET[\"max_area\"] = ([\"sample\", \"track\"], np.nanmax([DATASET[\"max_prev_area\"].values, DATASET[\"max_obs_area\"].values], axis=0))\n",
    "\n",
    "# Track lifetime\n",
    "DATASET[\"lifetime_prev\"] = DATASET[\"prev_mean_rr\"].count(dim=\"prev_time\")\n",
    "DATASET[\"lifetime_full\"] = DATASET[\"lifetime_prev\"] + DATASET[\"obs_lifetime\"]\n",
    "\n",
    "# Maximum RVR in track\n",
    "DATASET[\"track_max_prev_rr\"] = DATASET[\"prev_sum_rr\"].max(dim=\"prev_time\", skipna=True)\n",
    "DATASET[\"track_max_obs_rr\"] = DATASET[\"obs_sum_rr\"].max(dim=\"leadtime\", skipna=True)\n",
    "DATASET[\"track_max_pred_rr\"] = DATASET[\"pred_sum_rr\"].max(dim=\"leadtime\", skipna=True)\n",
    "DATASET[\"track_argmax_obs_rr\"] = DATASET[\"obs_sum_rr\"].fillna(-1000).argmax(dim=\"leadtime\", skipna=True).where(\n",
    "    DATASET[\"track_max_obs_rr\"] > 0)\n",
    "\n",
    "# Minimum RVR in track\n",
    "DATASET[\"track_min_prev_rr\"] = DATASET[\"prev_sum_rr\"].min(dim=\"prev_time\", skipna=True)\n",
    "DATASET[\"track_min_obs_rr\"] = DATASET[\"obs_sum_rr\"].min(dim=\"leadtime\", skipna=True)\n",
    "DATASET[\"track_min_pred_rr\"] = DATASET[\"pred_sum_rr\"].min(dim=\"leadtime\", skipna=True)\n",
    "\n",
    "# General variables\n",
    "DATASET = DATASET.where(DATASET.method.isin(conf.legend_order))\n",
    "N_METHODS = np.unique(DATASET.method.values).size\n",
    "METHODS = np.unique(DATASET.method.values)\n",
    "\n",
    "sorter = np.argsort(np.array(conf.legend_order))\n",
    "\n",
    "DATASET_BASE = DATASET.copy()\n",
    "DATASET_BASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_ = DATASET.copy()\n",
    "\n",
    "# State according to derivative definition\n",
    "derivative_at_t0 = xr.concat([\n",
    "    DATASET[\"prev_sum_rr\"].sel(prev_time=[-2, -1, 0]).rename({\"prev_time\": \"leadtime\"}), \n",
    "    DATASET[\"obs_sum_rr\"].sel(leadtime=[1, 2,])\n",
    "], dim=\"leadtime\").differentiate(\"leadtime\").sel(leadtime=0)\n",
    "\n",
    "num_point_in_derivative = xr.concat([\n",
    "    DATASET[\"prev_sum_rr\"].sel(prev_time=[-2, -1, 0]).rename({\"prev_time\": \"leadtime\"}), \n",
    "    DATASET[\"obs_sum_rr\"].sel(leadtime=[1, 2,])\n",
    "], dim=\"leadtime\").count(dim=\"leadtime\")\n",
    "\n",
    "ds_[\"obs_derivative_at_t0\"] = derivative_at_t0\n",
    "ds_[\"num_points_in_obs_derivative\"] = num_point_in_derivative\n",
    "\n",
    "growth_cond = derivative_at_t0 > 0\n",
    "decay_cond = (\n",
    "    ((derivative_at_t0) < 0) | \n",
    "    ((ds_[\"track_max_prev_rr\"] > 0) & (ds_[\"prev_sum_rr\"].sel(prev_time=0) > 0) & (derivative_at_t0.isnull()))\n",
    ")\n",
    "stable_cond = (\n",
    "    (np.abs(derivative_at_t0) == 0)\n",
    "    & ((ds_[\"track_max_prev_rr\"] > 0) & (ds_[\"track_max_obs_rr\"] > 0))\n",
    ")\n",
    "ds_[\"state\"] = xr.ones_like(ds_[\"track_max_prev_rr\"]) * np.nan\n",
    "ds_[\"state\"] = ds_[\"state\"].where(~growth_cond, \"growth\")\n",
    "ds_[\"state\"] = ds_[\"state\"].where(~decay_cond, \"decay\")\n",
    "ds_[\"state\"] = ds_[\"state\"].where(~stable_cond, \"stable\")\n",
    "\n",
    "# As integer for confusion matrix\n",
    "ds_[\"state_int\"] = xr.ones_like(ds_[\"track_max_prev_rr\"]) * np.nan\n",
    "ds_[\"state_int\"] = ds_[\"state_int\"].where(~growth_cond, 1)\n",
    "ds_[\"state_int\"] = ds_[\"state_int\"].where(~decay_cond, 2)\n",
    "ds_[\"state_int\"] = ds_[\"state_int\"].where(~stable_cond, 3)\n",
    "\n",
    "# Predicted state according to derivative definition\n",
    "# Predicted state per track\n",
    "derivative_pred_at_t0 = xr.concat([\n",
    "    DATASET[\"prev_sum_rr\"].sel(prev_time=[-2, -1, 0]).rename({\"prev_time\": \"leadtime\"}), \n",
    "    DATASET[\"pred_sum_rr\"].sel(leadtime=[1, 2,])\n",
    "], dim=\"leadtime\").differentiate(\"leadtime\").sel(leadtime=0)\n",
    "\n",
    "num_point_in_pred_derivative = xr.concat([\n",
    "    DATASET[\"prev_sum_rr\"].sel(prev_time=[-2, -1, 0]).rename({\"prev_time\": \"leadtime\"}), \n",
    "    DATASET[\"pred_sum_rr\"].sel(leadtime=[1, 2,])\n",
    "], dim=\"leadtime\").count(dim=\"leadtime\")\n",
    "\n",
    "ds_[\"pred_derivative_at_t0\"] = derivative_pred_at_t0\n",
    "ds_[\"num_points_in_pred_derivative\"] = num_point_in_pred_derivative\n",
    "growth_cond_pred = derivative_pred_at_t0 > 0\n",
    "decay_cond_pred = (\n",
    "    (derivative_pred_at_t0 < 0) | \n",
    "    ((ds_[\"track_max_prev_rr\"] > 0) &  (ds_[\"prev_sum_rr\"].sel(prev_time=0) > 0) & (derivative_pred_at_t0.isnull()))\n",
    ")\n",
    "stable_cond_pred = (\n",
    "    (np.abs(derivative_pred_at_t0) == 0) & \n",
    "    ((ds_[\"track_max_prev_rr\"] > 0) & (ds_[\"track_max_pred_rr\"] > 0))\n",
    ")\n",
    "\n",
    "ds_[\"state_pred\"] = xr.ones_like(ds_[\"track_max_prev_rr\"]) * np.nan\n",
    "ds_[\"state_pred\"] = ds_[\"state_pred\"].where(~growth_cond_pred, \"growth\")\n",
    "ds_[\"state_pred\"] = ds_[\"state_pred\"].where(~decay_cond_pred, \"decay\")\n",
    "ds_[\"state_pred\"] = ds_[\"state_pred\"].where(~stable_cond_pred, \"stable\")\n",
    "\n",
    "# As integer for confusion matrix\n",
    "ds_[\"state_pred_int\"] = xr.ones_like(ds_[\"track_max_prev_rr\"]) * np.nan\n",
    "ds_[\"state_pred_int\"] = ds_[\"state_pred_int\"].where(~growth_cond_pred, 1)\n",
    "ds_[\"state_pred_int\"] = ds_[\"state_pred_int\"].where(~decay_cond_pred, 2)\n",
    "ds_[\"state_pred_int\"] = ds_[\"state_pred_int\"].where(~stable_cond_pred, 3)\n",
    "\n",
    "DATASET_CELL_STATE = ds_.copy()\n",
    "\n",
    "DATASET_CELL_STATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for cell matching (without tracking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contingency scores (CSI, POD, FAR, BIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"../config/stylefiles/article.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hits = DATASET[\"cell_match_hits\"].sum(dim=\"sample\")\n",
    "misses = DATASET[\"cell_match_misses\"].sum(dim=\"sample\")\n",
    "falarms = DATASET[\"cell_match_false_alarms\"].sum(dim=\"sample\")\n",
    "\n",
    "csi = hits / (hits + misses + falarms)\n",
    "pod = hits / (hits + misses)\n",
    "far = falarms / (hits + falarms)\n",
    "bias = (hits + falarms) / (hits + misses)\n",
    "\n",
    "scores = {\n",
    "    \"CSI\": csi,\n",
    "    \"POD\": pod,\n",
    "    \"FAR\": far,\n",
    "    \"BIAS\": bias,\n",
    "}\n",
    "metrics = [\"CSI\", \"BIAS\", \"POD\", \"FAR\"]\n",
    "\n",
    "df = pd.concat([hits.to_dataframe(), misses.to_dataframe(), falarms.to_dataframe()], axis=1)\n",
    "df[\"total\"] = df[\"cell_match_hits\"] + df[\"cell_match_misses\"] + df[\"cell_match_false_alarms\"]\n",
    "\n",
    "df[\"hits_misses\"] = df[\"cell_match_hits\"] + df[\"cell_match_misses\"]\n",
    "df[\"hits_misses_falsealarms\"] = df[\"cell_match_hits\"] + df[\"cell_match_misses\"] + df[\"cell_match_false_alarms\"]\n",
    "\n",
    "sorter = np.argsort(np.array(conf.legend_order))\n",
    "n_leadtimes = DATASET_BASE.leadtime.values.size\n",
    "\n",
    "df.sort_values(\n",
    "    by=\"method\",\n",
    "    key=lambda x: sorter[\n",
    "        np.searchsorted(np.array(conf.legend_order), df.index.get_level_values(1), sorter=sorter)\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save cell counts to csv file\n",
    "store_df = df.copy()\n",
    "store_df.rename(columns={\"cell_match_hits\": \"hits\", \"cell_match_misses\": \"misses\", \"cell_match_false_alarms\": \"false_alarms\"}, inplace=True)\n",
    "\n",
    "outputname = \"cell_match_metrics_a_counts\"\n",
    "store_df.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")\n",
    "\n",
    "# Save cell metrics to csv file\n",
    "score_df = xr.merge([v.rename(k) for k, v in scores.items()]).to_dataframe().reset_index()\n",
    "\n",
    "outputname = \"cell_match_metrics_bcde_metrics\"\n",
    "score_df.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(layout=\"constrained\", figsize=(12, 18))\n",
    "\n",
    "axs = fig.subplot_mosaic([\n",
    "        # [\".\", \"counts\", \"counts\", \"counts\", \"counts\", \".\"],\n",
    "        # [\"CSI\", \"CSI\", \"POD\",\"POD\", \"FAR\",\"FAR\"],\n",
    "        [\".\", \"counts\", \"counts\", \".\"],\n",
    "        [\"CSI\", \"CSI\", \"BIAS\", \"BIAS\"],\n",
    "        [\"POD\", \"POD\", \"FAR\", \"FAR\"],\n",
    "    ], \n",
    "    # width_ratios=[0.2, 0.1, 0.15, 0.15, 0.1, 0.2],\n",
    "    # height_ratios=[0.5, 0.5],\n",
    "    # width_ratios=[0.5, 0.5],\n",
    "    width_ratios=[0.2, 0.25, 0.25, 0.2],\n",
    "    height_ratios=[6, 6, 6,],\n",
    "    # gridspec_kw={'wspace': 0.0, \"w_pad\": 0}\n",
    ")\n",
    "axs[\"POD\"].sharey(axs[\"FAR\"])\n",
    "# axs[\"POD\"].sharey(axs[\"CSI\"])\n",
    "# axs[\"FAR\"].sharey(axs[\"CSI\"])\n",
    "# axs[\"POD\"].sharex(axs[\"CSI\"])\n",
    "# axs[\"FAR\"].sharex(axs[\"CSI\"])\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axs[metric]\n",
    "    df_ = scores[metric]\n",
    "    # Change leadtime to minutes\n",
    "    df_[\"leadtime_\"] = df_[\"leadtime\"] * 5\n",
    "    for model in conf.legend_order:\n",
    "        df_.sel(dict(method=model)).plot.line(\n",
    "            ax=ax,\n",
    "            x=\"leadtime_\",\n",
    "            color=conf.methods[model][\"color\"],\n",
    "            label=conf.methods[model][\"label\"],\n",
    "            linestyle=conf.methods[model][\"linestyle\"],\n",
    "        )\n",
    "    set_ax(ax, conf.metric_conf[metric], [5, 60], conf.leadtime_locator_multiples)\n",
    "    ax.set_ylabel(conf.metric_conf[metric][\"label\"])\n",
    "    ax.set_title(f'({alphabet[1+i]}) {conf.metric_conf[metric][\"full_name\"]}', color=plt.rcParams[\"axes.titlecolor\"])\n",
    "    ax.grid(which=\"both\", axis=\"both\")\n",
    "    ax.legend()\n",
    "\n",
    "\n",
    "# False alarms\n",
    "g_falarms = sns.barplot(\n",
    "    ax=axs[\"counts\"], \n",
    "    data=df, \n",
    "    x=\"method\", \n",
    "    hue=\"leadtime\", \n",
    "    y=\"hits_misses_falsealarms\", \n",
    "    palette=[\"w\"]*n_leadtimes, \n",
    "    edgecolor=\"black\", \n",
    "    linewidth=0.5, \n",
    "    legend=False,\n",
    ")\n",
    "# Misses\n",
    "g_misses = sns.barplot(\n",
    "    ax=axs[\"counts\"], \n",
    "    data=df, \n",
    "    x=\"method\", \n",
    "    hue=\"leadtime\", \n",
    "    y=\"hits_misses\", \n",
    "    palette=[\"tab:gray\"]*n_leadtimes, \n",
    "    edgecolor=\"black\", \n",
    "    linewidth=0.5, \n",
    "    legend=False,\n",
    ")\n",
    "# Hits\n",
    "g_hits = sns.barplot(\n",
    "    ax=axs[\"counts\"], \n",
    "    data=df, \n",
    "    x=\"method\", \n",
    "    hue=\"leadtime\", \n",
    "    y=\"cell_match_hits\", \n",
    "    palette=HUE_CMAP, \n",
    "    edgecolor=\"black\", \n",
    "    linewidth=0.5, \n",
    "    legend=\"full\"\n",
    ")\n",
    "\n",
    "axs[\"counts\"].set_title(f\"(a) Cell counts\")\n",
    "axs[\"counts\"].set_xticklabels(\n",
    "    [get_labelstr(l.get_text()) for l in axs[\"counts\"].get_xticklabels()]\n",
    ")\n",
    "g_hits.axes.get_legend().remove()\n",
    "\n",
    "h, l = axs[\"counts\"].get_legend_handles_labels()\n",
    "l1 = fig.legend(\n",
    "    h,\n",
    "    [leadtime_to_minutes((int(s)), 0) for s in l],\n",
    "    title=\"Leadtime [min]\",\n",
    "    bbox_to_anchor=(0.8, 0.8),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=1,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "fig.add_artist(l1)\n",
    "\n",
    "axs[\"counts\"].set_autoscale_on(False)\n",
    "axs[\"counts\"].set_ylim(0, 370e3)\n",
    "axs[\"counts\"].set_ylabel(COUNT_TITLE)\n",
    "# ax.set_ylim(LIFETIME_LIMITS)\n",
    "# ax.yaxis.set_major_locator(ticker.MultipleLocator(LIFETIME_TICK_MULTIPLE))\n",
    "axs[\"counts\"].yaxis.set_major_locator(ticker.MultipleLocator(50e3))\n",
    "axs[\"counts\"].yaxis.set_minor_locator(ticker.MultipleLocator(10e3))\n",
    "axs[\"counts\"].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f\"{x / 1000:.0f}\"))\n",
    "axs[\"counts\"].grid(which=\"major\", axis=\"y\")\n",
    "axs[\"counts\"].grid(which=\"minor\", axis=\"y\", alpha=0.2)\n",
    "axs[\"counts\"].set_autoscale_on(False)\n",
    "axs[\"counts\"].set_xlabel(METHOD_X_LABEL)\n",
    "    \n",
    "# Make legend for hits, misses, false alarms, correct negatives labels\n",
    "palette_hue = sns.color_palette(HUE_CMAP, n_leadtimes)\n",
    "hits_patch = [patches.Patch(facecolor=c, edgecolor=c, label=\"Hits\") for c in palette_hue]\n",
    "\n",
    "misses_patch = patches.Patch(facecolor=\"tab:gray\", edgecolor=\"tab:gray\", label=\"Misses\")\n",
    "falarms_patch = patches.Patch(facecolor=\"white\", edgecolor=\"k\", label=\"False alarms\")\n",
    "# cnegs_patch = patches.Patch(facecolor=\"k\", edgecolor=\"tab:gray\", label=\"Correct negatives\")\n",
    "\n",
    "other_patches = [misses_patch, falarms_patch]\n",
    "\n",
    "leg = fig.legend(\n",
    "    handles=[hits_patch, *other_patches], \n",
    "    labels=[\"Hits\", *[p.get_label() for p in other_patches]], \n",
    "    handler_map={list: HandlerTuple(ndivide=None, pad=0)},\n",
    "    ncols=1,\n",
    "    bbox_to_anchor=(0.8, 0.95),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "\n",
    "outputname = \"cell_match_metrics\"\n",
    "save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures for cell tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical scores of cell existence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"../config/stylefiles/article.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "track_exists_cond = (DATASET_CELL_STATE[\"track_max_prev_rr\"] > 0) & ((DATASET_CELL_STATE[\"prev_sum_rr\"].sel(prev_time=0) > 0))\n",
    "\n",
    "cell_exists_nowcast = (DATASET_CELL_STATE[\"pred_sum_rr\"] > 0) \n",
    "cell_exists_obs = (DATASET_CELL_STATE[\"obs_sum_rr\"] > 0)\n",
    "\n",
    "cell_exists_nowcast = cell_exists_nowcast.where(track_exists_cond, 2)\n",
    "cell_exists_obs = cell_exists_obs.where(track_exists_cond, 2)\n",
    "\n",
    "contingency_all = xs.Contingency(\n",
    "    cell_exists_obs, \n",
    "    cell_exists_nowcast, \n",
    "    np.array([0, 0.5, 1.0]), \n",
    "    np.array([0, 0.5, 1.0]), \n",
    "    dim=[\"sample\", \"track\"],\n",
    ")\n",
    "contingency_all.table\n",
    "\n",
    "track_exists_growth_cond = (DATASET_CELL_STATE[\"track_max_prev_rr\"] > 0) & (DATASET_CELL_STATE[\"state\"] == \"growth\")\n",
    "\n",
    "cell_exists_nowcast = (DATASET_CELL_STATE[\"pred_sum_rr\"] > 0) \n",
    "cell_exists_obs = (DATASET_CELL_STATE[\"obs_sum_rr\"] > 0)\n",
    "\n",
    "cell_exists_nowcast = cell_exists_nowcast.where(track_exists_growth_cond, 2)\n",
    "cell_exists_obs = cell_exists_obs.where(track_exists_growth_cond, 2)\n",
    "\n",
    "contingency_growth = xs.Contingency(\n",
    "    cell_exists_obs, \n",
    "    cell_exists_nowcast, \n",
    "    np.array([0, 0.5, 1.0]), \n",
    "    np.array([0, 0.5, 1.0]), \n",
    "    dim=[\"sample\", \"track\"],\n",
    ")\n",
    "contingency_growth.table\n",
    "\n",
    "track_exists_decay_cond = (DATASET_CELL_STATE[\"track_max_prev_rr\"] > 0) & (DATASET_CELL_STATE[\"state\"] == \"decay\")\n",
    "\n",
    "cell_exists_nowcast = (DATASET_CELL_STATE[\"pred_sum_rr\"] > 0) \n",
    "cell_exists_obs = (DATASET_CELL_STATE[\"obs_sum_rr\"] > 0)\n",
    "\n",
    "cell_exists_nowcast = cell_exists_nowcast.where(track_exists_decay_cond, 2)\n",
    "cell_exists_obs = cell_exists_obs.where(track_exists_decay_cond, 2)\n",
    "\n",
    "contingency_decay = xs.Contingency(\n",
    "    cell_exists_obs, \n",
    "    cell_exists_nowcast, \n",
    "    np.array([0, 0.5, 1.0]), \n",
    "    np.array([0, 0.5, 1.0]), \n",
    "    dim=[\"sample\", \"track\"],\n",
    ")\n",
    "contingency_decay.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bar plot of fractions of hits, misses, false alarms, and correct negatives\n",
    "# for each leadtime\n",
    "\n",
    "contingency_tables = {\n",
    "    \"all\": contingency_all, \n",
    "    \"decay\": contingency_decay, \n",
    "    \"growth\": contingency_growth\n",
    "}\n",
    "\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=len(contingency_tables),\n",
    "    nrows=1,\n",
    "    # figsize=(W_PER_METHOD_S * N_METHODS, FIG_HEIGHT * len(groups)),\n",
    "    figsize=((FIG_WIDTH+0.2) * len(contingency_tables), FIG_HEIGHT * 1),\n",
    "    constrained_layout=True,\n",
    "    sharey=\"row\",\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "sorter = np.argsort(np.array(conf.legend_order))\n",
    "\n",
    "n_leadtimes = DATASET_BASE.leadtime.values.size\n",
    "\n",
    "store_dfs = {}\n",
    "\n",
    "for i, (name, contingency) in enumerate(contingency_tables.items()):\n",
    "    ax = axs[0, i]\n",
    "    \n",
    "    hits = contingency.hits()\n",
    "    misses = contingency.misses()\n",
    "    false_alarms = contingency.false_alarms()\n",
    "    correct_non_alarms = contingency.correct_negatives()\n",
    "\n",
    "    df = pd.concat([hits.to_dataframe(), misses.to_dataframe(), false_alarms.to_dataframe(), correct_non_alarms.to_dataframe()], axis=1)\n",
    "    df.columns = [\"hits\", \"misses\", \"false_alarms\", \"correct_negatives\"]\n",
    "\n",
    "    df[\"total\"] = df[\"hits\"] + df[\"misses\"] + df[\"false_alarms\"] + df[\"correct_negatives\"]\n",
    "\n",
    "    df[\"hits_frac\"] = df[\"hits\"]# / df[\"total\"]\n",
    "    df[\"misses_frac\"] = df[\"misses\"]# / df[\"total\"]\n",
    "    df[\"false_alarms_frac\"] = df[\"false_alarms\"]# / df[\"total\"]\n",
    "    df[\"correct_negatives_frac\"] = df[\"correct_negatives\"]# / df[\"total\"]\n",
    "\n",
    "    df[\"hits_misses\"] = df[\"hits_frac\"] + df[\"misses_frac\"]\n",
    "    df[\"hits_misses_falsealarms\"] = df[\"hits_frac\"] + df[\"misses_frac\"] + df[\"false_alarms_frac\"]\n",
    "    df[\"hits_misses_correctnegatives\"] = df[\"hits_frac\"] + df[\"misses_frac\"] + df[\"false_alarms_frac\"] + df[\"correct_negatives_frac\"]\n",
    "    \n",
    "    df.sort_values(\n",
    "        by=\"method\",\n",
    "        key=lambda x: sorter[\n",
    "            np.searchsorted(np.array(conf.legend_order), df.index.get_level_values(1), sorter=sorter)\n",
    "        ],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    store_dfs[name] = df.copy()\n",
    "    \n",
    "    # This shows up as correct negatives\n",
    "    g_cnegs = sns.barplot(\n",
    "        ax=ax, \n",
    "        data=df, \n",
    "        x=\"method\", \n",
    "        hue=\"leadtime\", \n",
    "        y=\"hits_misses_correctnegatives\", \n",
    "        palette=[\"k\"]*n_leadtimes, \n",
    "        edgecolor=\"tab:gray\", \n",
    "        linewidth=0.5, \n",
    "        legend=False,\n",
    "    )\n",
    "    # False alarms\n",
    "    g_falarms = sns.barplot(\n",
    "        ax=ax, \n",
    "        data=df, \n",
    "        x=\"method\", \n",
    "        hue=\"leadtime\", \n",
    "        y=\"hits_misses_falsealarms\", \n",
    "        palette=[\"w\"]*n_leadtimes, \n",
    "        edgecolor=\"black\", \n",
    "        linewidth=0.5, \n",
    "        legend=False,\n",
    "    )\n",
    "    # Misses\n",
    "    g_misses = sns.barplot(\n",
    "        ax=ax, \n",
    "        data=df, \n",
    "        x=\"method\", \n",
    "        hue=\"leadtime\", \n",
    "        y=\"hits_misses\", \n",
    "        palette=[\"tab:gray\"]*n_leadtimes, \n",
    "        edgecolor=\"black\", \n",
    "        linewidth=0.5, \n",
    "        legend=False,\n",
    "    )\n",
    "    # Hits\n",
    "    g_hits = sns.barplot(\n",
    "        ax=ax, \n",
    "        data=df, \n",
    "        x=\"method\", \n",
    "        hue=\"leadtime\", \n",
    "        y=\"hits_frac\", \n",
    "        palette=HUE_CMAP, \n",
    "        edgecolor=\"black\", \n",
    "        linewidth=0.5, \n",
    "        legend=\"full\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"({alphabet[i]}) {STATE_GROUP_TITLES[name]}\")\n",
    "    ax.set_xticklabels(\n",
    "        [get_labelstr(l.get_text()) for l in ax.get_xticklabels()]\n",
    "    )\n",
    "    g_hits.axes.get_legend().remove()\n",
    "\n",
    "h, l = axs.flatten()[-1].get_legend_handles_labels()\n",
    "l1 = fig.legend(\n",
    "    h,\n",
    "    [leadtime_to_minutes((int(s)), 0) for s in l],\n",
    "    title=\"Leadtime [min]\",\n",
    "    bbox_to_anchor=(0.43, 1.08),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=6,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "fig.add_artist(l1)\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.set_autoscale_on(False)\n",
    "    ax.set_ylim(0, 160e3)\n",
    "    ax.set_ylabel(COUNT_TITLE)\n",
    "    # ax.set_ylim(LIFETIME_LIMITS)\n",
    "    # ax.yaxis.set_major_locator(ticker.MultipleLocator(LIFETIME_TICK_MULTIPLE))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(25e3))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(5e3))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f\"{x / 1000:.0f}\"))\n",
    "    ax.grid(which=\"major\", axis=\"y\")\n",
    "    ax.grid(which=\"minor\", axis=\"y\", alpha=0.2)\n",
    "    ax.set_autoscale_on(False)\n",
    "    ax.set_xlabel(METHOD_X_LABEL)\n",
    "    \n",
    "# Make legend for hits, misses, false alarms, correct negatives labels\n",
    "palette_hue = sns.color_palette(HUE_CMAP, n_leadtimes)\n",
    "hits_patch = [patches.Patch(facecolor=c, edgecolor=c, label=\"Hits\") for c in palette_hue]\n",
    "\n",
    "misses_patch = patches.Patch(facecolor=\"tab:gray\", edgecolor=\"tab:gray\", label=\"Misses\")\n",
    "falarms_patch = patches.Patch(facecolor=\"white\", edgecolor=\"k\", label=\"False alarms\")\n",
    "cnegs_patch = patches.Patch(facecolor=\"k\", edgecolor=\"tab:gray\", label=\"Correct negatives\")\n",
    "\n",
    "other_patches = [misses_patch, falarms_patch, cnegs_patch]\n",
    "\n",
    "leg = fig.legend(\n",
    "    handles=[hits_patch, *other_patches], \n",
    "    labels=[\"Hits\", *[p.get_label() for p in other_patches]], \n",
    "    handler_map={list: HandlerTuple(ndivide=None, pad=0)},\n",
    "    ncols=2,\n",
    "    bbox_to_anchor=(0.18, 1.08),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    fontsize=\"large\",\n",
    ")\n",
    "\n",
    "outputname = \"cell_existence_counts\"\n",
    "save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "store_df = pd.concat(store_dfs.values(), keys=store_dfs.keys(), axis=0).reset_index()\n",
    "store_df.rename(columns={\"level_0\": \"state\"}, inplace=True)\n",
    "\n",
    "outputname = \"cell_existence_counts\"\n",
    "store_df.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"../config/stylefiles/article.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# metrics = [\"CSI\", \"ETS\", \"POD\", \"FAR\"]\n",
    "metrics = [\"CSI\", \"BIAS\", \"POD\", \"FAR\"]\n",
    "\n",
    "conf.metric_conf[\"BIAS\"][\"limits\"] = [0.5, 6.0]\n",
    "conf.metric_conf[\"BIAS\"][\"ticks\"] = [0.5, 0.25]\n",
    "                         \n",
    "contingency_tables = {\n",
    "    \"all\": contingency_all, \n",
    "    \"decay\": contingency_decay, \n",
    "    \"growth\": contingency_growth\n",
    "}\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    figsize=(len(contingency_tables.keys())*5, len(metrics)*5), \n",
    "    nrows=len(metrics), \n",
    "    ncols=len(contingency_tables.keys()), \n",
    "    layout=\"compressed\",\n",
    "    sharey=\"row\",\n",
    "    sharex=True,\n",
    ")\n",
    "\n",
    "store_dfs = {}\n",
    "\n",
    "for j, (name, contingency) in enumerate(contingency_tables.items()):\n",
    "\n",
    "    dfs = {\n",
    "        \"CSI\": contingency.threat_score(),\n",
    "        # \"ETS\": contingency.equit_threat_score(),\n",
    "        \"POD\": contingency.hit_rate(),\n",
    "        \"FAR\": contingency.false_alarm_ratio(),\n",
    "        \"BIAS\": contingency.bias_score(),\n",
    "    }\n",
    "    \n",
    "    store_dfs[name] = dfs.copy()\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axs[i, j]\n",
    "        df_ = dfs[metric]\n",
    "        # Change leadtime to minutes\n",
    "        df_[\"leadtime_min\"] = df_[\"leadtime\"] * 5\n",
    "        for model in conf.legend_order:\n",
    "            df_.sel(dict(method=model)).plot.line(\n",
    "                ax=ax,\n",
    "                x=\"leadtime_min\",\n",
    "                color=conf.methods[model][\"color\"],\n",
    "                label=conf.methods[model][\"label\"],\n",
    "                linestyle=conf.methods[model][\"linestyle\"],\n",
    "            )\n",
    "        set_ax(ax, conf.metric_conf[metric], [5, 60], conf.leadtime_locator_multiples)\n",
    "        ax.set_ylabel(conf.metric_conf[metric][\"label\"])\n",
    "        ax.set_title(f'({alphabet[i*3 + j]}) {STATE_GROUP_TITLES[name]}: {conf.metric_conf[metric][\"full_name\"]}', color=plt.rcParams[\"axes.titlecolor\"])\n",
    "        ax.grid(which=\"both\", axis=\"both\")\n",
    "        ax.xaxis.set_tick_params(which='both', labelbottom=True)\n",
    "        ax.legend()\n",
    "        ax.yaxis.set_tick_params(which='both', labelbottom=True)\n",
    "        ax.xaxis.set_tick_params(which='both', labelbottom=True)\n",
    "        # ax.label_outer()\n",
    "\n",
    "outputname = \"cell_existence_growth_decay\"\n",
    "save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "store_df = pd.concat([xr.merge([v.rename(k) for k, v in store_dfs[state].items()]).to_dataframe() for state in store_dfs.keys()], keys=store_dfs.keys(), axis=0).reset_index()\n",
    "\n",
    "store_df.rename(columns={\"level_0\": \"state\"}, inplace=True)\n",
    "outputname = \"cell_existence_growth_decay\"\n",
    "store_df.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contingency scores of cell track decay/growth classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contingency = xs.Contingency(\n",
    "    DATASET_CELL_STATE[\"state_int\"], \n",
    "    DATASET_CELL_STATE[\"state_pred_int\"], \n",
    "    np.array([1, 2, 2.5]), \n",
    "    np.array([1, 2, 2.5]), \n",
    "    dim=[\"sample\", \"track\"],\n",
    ")\n",
    "# contingency.table.to_dataframe()\n",
    "\n",
    "\n",
    "scores = {\n",
    "    \"csi_growth\": contingency.threat_score(yes_category=1),\n",
    "    \"csi_decay\": contingency.threat_score(yes_category=2),\n",
    "    \"pod_growth\": contingency.hit_rate(yes_category=1),\n",
    "    \"pod_decay\": contingency.hit_rate(yes_category=2),\n",
    "    \n",
    "    \"ets\": contingency.equit_threat_score(yes_category=1),\n",
    "    \"gerrity\": contingency.gerrity_score(),\n",
    "    # \"peirce\": contingency.peirce_score(),\n",
    "    # \"heidke\": contingency.heidke_score(),\n",
    "    \"bias_growth\": contingency.bias_score(yes_category=1),\n",
    "    \"bias_decay\": contingency.bias_score(yes_category=2),\n",
    "    \n",
    "    \"far_growth\": contingency.false_alarm_ratio(yes_category=1),\n",
    "    \"far_decay\": contingency.false_alarm_ratio(yes_category=2),\n",
    "}\n",
    "\n",
    "score_names = {\n",
    "    \"csi_growth\": \"CSI for growth\",\n",
    "    \"csi_decay\": \"CSI for decay\",\n",
    "    \"pod_growth\": \"POD for growth\",\n",
    "    \"pod_decay\": \"POD for decay\",\n",
    "    \"far_growth\": \"FAR for growth\",\n",
    "    \"far_decay\": \"FAR for decay\",\n",
    "    \"bias_growth\": \"BIAS for growth\",\n",
    "    \"bias_decay\": \"BIAS for decay\",\n",
    "    \"ets\": \"ETS\",\n",
    "    \"gerrity\": \"Gerrity score\",\n",
    "    # \"peirce\": \"Peirce's skill score\",\n",
    "    # \"heidke\": \"Heidke skill score\",\n",
    "}\n",
    "\n",
    "print_df = pd.DataFrame(columns=conf.legend_order, index=list(scores.keys()))\n",
    "for score, df_ in scores.items():\n",
    "    for model in conf.legend_order:\n",
    "        print_df.loc[score, model] = df_.loc[model].item()\n",
    "        \n",
    "df_ = print_df.melt(ignore_index=False).reset_index()\n",
    "# df_\n",
    "\n",
    "yes_values = {\n",
    "    \"decay\": 2, \n",
    "    \"growth\": 1,\n",
    "}\n",
    "\n",
    "sorter = np.argsort(np.array(conf.legend_order))\n",
    "n_leadtimes = DATASET_BASE.leadtime.values.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(layout=\"constrained\", figsize=(12, 11))\n",
    "\n",
    "axs = fig.subplot_mosaic([\n",
    "        [\"decay\", \"decay\", \"growth\",\"growth\"],\n",
    "        [\".\", \"scores\", \"scores\", \".\"],\n",
    "    ], \n",
    "    width_ratios=[0.01, 0.49, 0.49, 0.01],\n",
    "    height_ratios=[0.4, 0.6],\n",
    "    # gridspec_kw={'wspace': 0.0, \"w_pad\": 0}\n",
    ")\n",
    "\n",
    "store_dfs = {}\n",
    "\n",
    "for i, (name, yes) in enumerate(yes_values.items()):\n",
    "    ax = axs[name]\n",
    "    \n",
    "    hits = contingency.hits(yes_category=yes)\n",
    "    misses = contingency.misses(yes_category=yes)\n",
    "    false_alarms = contingency.false_alarms(yes_category=yes)\n",
    "    correct_non_alarms = contingency.correct_negatives(yes_category=yes)\n",
    "\n",
    "    df = pd.concat([hits.to_dataframe(), misses.to_dataframe(), false_alarms.to_dataframe(), correct_non_alarms.to_dataframe()], axis=1)\n",
    "    df.columns = [\"hits\", \"misses\", \"false_alarms\", \"correct_negatives\"]\n",
    "\n",
    "    df[\"total\"] = df[\"hits\"] + df[\"misses\"] + df[\"false_alarms\"] + df[\"correct_negatives\"]\n",
    "\n",
    "    df[\"hits_frac\"] = df[\"hits\"]# / df[\"total\"]\n",
    "    df[\"misses_frac\"] = df[\"misses\"]# / df[\"total\"]\n",
    "    df[\"false_alarms_frac\"] = df[\"false_alarms\"]# / df[\"total\"]\n",
    "    df[\"correct_negatives_frac\"] = df[\"correct_negatives\"]# / df[\"total\"]\n",
    "\n",
    "    df[\"hits_misses\"] = df[\"hits_frac\"] + df[\"misses_frac\"]\n",
    "    df[\"hits_misses_falsealarms\"] = df[\"hits_frac\"] + df[\"misses_frac\"] + df[\"false_alarms_frac\"]\n",
    "    df[\"hits_misses_correctnegatives\"] = df[\"hits_frac\"] + df[\"misses_frac\"] + df[\"false_alarms_frac\"] + df[\"correct_negatives_frac\"]\n",
    "    \n",
    "    df.sort_values(\n",
    "        by=\"method\",\n",
    "        key=lambda x: sorter[\n",
    "            np.searchsorted(np.array(conf.legend_order), df.index.get_level_values(0), sorter=sorter)\n",
    "        ],\n",
    "        inplace=True,\n",
    "    )\n",
    "    store_dfs[name] = df.copy()\n",
    "    \n",
    "    # This shows up as correct negatives\n",
    "    g_cnegs = sns.barplot(\n",
    "        ax=ax, \n",
    "        data=df, \n",
    "        x=\"method\", \n",
    "        hue=\"method\",\n",
    "        y=\"hits_misses_correctnegatives\", \n",
    "        palette=[\"k\"]*n_leadtimes, \n",
    "        edgecolor=\"tab:gray\", \n",
    "        linewidth=0.5, \n",
    "        legend=False,\n",
    "    )\n",
    "    # False alarms\n",
    "    g_falarms = sns.barplot(\n",
    "        ax=ax, \n",
    "        data=df, \n",
    "        x=\"method\", \n",
    "        hue=\"method\",\n",
    "        y=\"hits_misses_falsealarms\", \n",
    "        palette=[\"w\"]*n_leadtimes, \n",
    "        edgecolor=\"black\", \n",
    "        linewidth=0.5, \n",
    "        legend=False,\n",
    "    )\n",
    "    # Misses\n",
    "    g_misses = sns.barplot(\n",
    "        ax=ax, \n",
    "        data=df, \n",
    "        x=\"method\", \n",
    "        hue=\"method\",  \n",
    "        y=\"hits_misses\", \n",
    "        palette=[\"tab:gray\"]*n_leadtimes, \n",
    "        edgecolor=\"black\", \n",
    "        linewidth=0.5, \n",
    "        legend=False,\n",
    "    )\n",
    "    # Hits\n",
    "    g_hits = sns.barplot(\n",
    "        ax=ax, \n",
    "        data=df, \n",
    "        x=\"method\", \n",
    "        hue=\"method\", \n",
    "        y=\"hits_frac\", \n",
    "        palette=COLORS_METHODS, \n",
    "        edgecolor=\"black\", \n",
    "        linewidth=0.5, \n",
    "        legend=\"full\"\n",
    "    )\n",
    "    ax.set_title(f\"({alphabet[i]}) {STATE_GROUP_TITLES[name]} classification track counts\")\n",
    "    ax.set_xticklabels(\n",
    "        [get_labelstr(l.get_text()) for l in ax.get_xticklabels()]\n",
    "    )\n",
    "    g_hits.axes.get_legend().remove()\n",
    "\n",
    "for ax in [axs[\"decay\"], axs[\"growth\"]]:\n",
    "    ax.set_autoscale_on(False)\n",
    "    ax.set_ylim(0, 160e3)\n",
    "    # ax.set_ylim(LIFETIME_LIMITS)\n",
    "    # ax.yaxis.set_major_locator(ticker.MultipleLocator(LIFETIME_TICK_MULTIPLE))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(25e3))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(5e3))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f\"{x / 1000:.0f}\"))\n",
    "    ax.grid(which=\"major\", axis=\"y\")\n",
    "    ax.grid(which=\"minor\", axis=\"y\", alpha=0.2)\n",
    "    ax.set_autoscale_on(False)\n",
    "    ax.set_xlabel(METHOD_X_LABEL)\n",
    "    ax.set_ylabel(COUNT_TITLE)\n",
    "    # ax.label_outer()\n",
    "    \n",
    "# Make legend for hits, misses, false alarms, correct negatives labels\n",
    "palette_hue = sns.color_palette([COLORS_METHODS[n] for n in METHODS])\n",
    "hits_patch = [patches.Patch(facecolor=c, edgecolor=c, label=\"Hits\") for c in palette_hue]\n",
    "\n",
    "misses_patch = patches.Patch(facecolor=\"tab:gray\", edgecolor=\"tab:gray\", label=\"Misses\")\n",
    "falarms_patch = patches.Patch(facecolor=\"white\", edgecolor=\"k\", label=\"False alarms\")\n",
    "cnegs_patch = patches.Patch(facecolor=\"k\", edgecolor=\"tab:gray\", label=\"Correct negatives\")\n",
    "\n",
    "other_patches = [misses_patch, falarms_patch, cnegs_patch]\n",
    "\n",
    "leg = fig.legend(\n",
    "    handles=[hits_patch, *other_patches], \n",
    "    labels=[\"Hits\", *[p.get_label() for p in other_patches]], \n",
    "    handler_map={list: HandlerTuple(ndivide=None, pad=0)},\n",
    "    ncols=2,\n",
    "    bbox_to_anchor=(0.51, 1.04),\n",
    "    loc=\"center\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "axs[\"decay\"].sharey(axs[\"growth\"])\n",
    "axs[\"growth\"].sharey(axs[\"decay\"])\n",
    "\n",
    "# Third panel for scores\n",
    "g = sns.barplot(\n",
    "    data=df_,\n",
    "    x=\"value\",\n",
    "    y=\"index\",\n",
    "    hue=\"variable\",\n",
    "    palette=COLORS_METHODS,\n",
    "    ax=axs[\"scores\"],\n",
    "    width=0.7,\n",
    "    edgecolor=\"k\",\n",
    "    linewidth=0.5,\n",
    "    gap=0.05,\n",
    ")\n",
    "\n",
    "offsets = [-0.225, -0.03, 0.15, 0.34]\n",
    "\n",
    "# Label bars so that the highest value is bold\n",
    "for ind, row in df_.iterrows():\n",
    "    val = row[\"value\"]\n",
    "    model = row[\"variable\"]\n",
    "    model_ind = conf.legend_order.index(model)\n",
    "    score = row[\"index\"]\n",
    "    score_ind = list(scores.keys()).index(score)\n",
    "    fontweight = \"normal\"\n",
    "    if \"bias\" in score:\n",
    "        df_[\"diff_from_one\"] = np.abs(df_[\"value\"] - 1).astype(float)\n",
    "        if val == df_.loc[df_.groupby(\"index\")[\"diff_from_one\"].idxmin(axis=0).loc[score], \"value\"]:\n",
    "            fontweight = \"bold\"\n",
    "    elif \"far\" not in score:\n",
    "        if val == df_.groupby(\"index\").max().loc[score, \"value\"]:\n",
    "            fontweight = \"bold\"\n",
    "    else:\n",
    "        if val == df_.groupby(\"index\").min().loc[score, \"value\"]:\n",
    "            fontweight = \"bold\"\n",
    "        \n",
    "    t = axs[\"scores\"].text(val + 0.01, score_ind + offsets[model_ind], f\"{val:.3f}\", fontweight=fontweight, fontsize=\"x-small\")\n",
    "    t.set_linespacing(1.0)\n",
    "    # t.set_bbox(dict(facecolor='white', alpha=0.8, edgecolor='white'))\n",
    "    # t.set_backgroundcolor(\"white\")\n",
    "    \n",
    "axs[\"scores\"].set_xlabel(\"Value\")\n",
    "axs[\"scores\"].set_ylabel(\"\")\n",
    "axs[\"scores\"].set_xlim(0, 1.3)\n",
    "axs[\"scores\"].xaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
    "axs[\"scores\"].xaxis.set_minor_locator(plt.MultipleLocator(0.05))\n",
    "axs[\"scores\"].grid(which=\"both\", axis=\"x\")\n",
    "axs[\"scores\"].axvline(1, color=\"gray\", linewidth=1.0, linestyle=\"--\")\n",
    "\n",
    "# horizontal line before bias scores\n",
    "axs[\"scores\"].axhline(\n",
    "    y=list(scores.keys()).index(\"bias_growth\") - 0.5, \n",
    "    color=\"gray\", \n",
    "    linewidth=1.0, linestyle=\"--\"\n",
    ")\n",
    "\n",
    "# horizontal line before far scores\n",
    "axs[\"scores\"].axhline(\n",
    "    y=list(scores.keys()).index(\"far_growth\") - 0.5, \n",
    "    color=\"gray\", \n",
    "    linewidth=1.0, linestyle=\"--\"\n",
    ")\n",
    "\n",
    "# Set y axis labels\n",
    "axs[\"scores\"].set_yticklabels([score_names[l_.get_text()] for l_ in axs[\"scores\"].get_yticklabels()])\n",
    "\n",
    "# Set title\n",
    "axs[\"scores\"].set_title(\"(c) Cell track classification metric values\")\n",
    "\n",
    "h, l = axs[\"scores\"].get_legend_handles_labels()\n",
    "l = [get_labelstr(l_) for l_ in l]\n",
    "axs[\"scores\"].legend(h, l)\n",
    "\n",
    "outputname = \"growth_decay_track_classification\"\n",
    "save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "\n",
    "# Cell counts\n",
    "store_df = pd.concat(store_dfs.values(), keys=store_dfs.keys(), axis=0)[[\"hits\", \"misses\", \"false_alarms\", \"correct_negatives\"]].reset_index()\n",
    "store_df.rename(columns={\"level_0\": \"state\"}, inplace=True)\n",
    "\n",
    "outputname = \"growth_decay_track_classification_ab_counts\"\n",
    "store_df.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")\n",
    "\n",
    "# Scores\n",
    "outputname = \"growth_decay_track_classification_c_scores\"\n",
    "df_.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE errors of feature values for all cells and by cell state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"area\", \"mean_rr\", \"sum_rr\"]\n",
    "\n",
    "errors_base = {}\n",
    "errors_state = defaultdict(dict)\n",
    "\n",
    "for var in variables:\n",
    "    ds_cs = DATASET_CELL_STATE[[f\"pred_{var}\", f\"obs_{var}\", \"state\"]].where((DATASET_CELL_STATE[f\"pred_{var}\"] > 0) & (DATASET_CELL_STATE[f\"obs_{var}\"] > 0))\n",
    "    ds_cs = ds_cs.fillna(0)\n",
    "    ds_cs = ds_cs.where((ds_cs[f\"pred_{var}\"] > 0) | (ds_cs[f\"obs_{var}\"] > 0), other=np.nan)\n",
    "    \n",
    "    ds_ = DATASET_BASE[[f\"pred_{var}\", f\"obs_{var}\"]].where((DATASET_BASE[f\"pred_{var}\"] > 0) & (DATASET_BASE[f\"obs_{var}\"] > 0))\n",
    "    ds_ = ds_.fillna(0)\n",
    "    ds_ = ds_.where((ds_[f\"pred_{var}\"] > 0) | (ds_[f\"obs_{var}\"] > 0), other=np.nan)\n",
    "    \n",
    "    ds_cs_growth = xr.where(ds_cs[\"state\"] == \"growth\", ds_cs, np.nan)\n",
    "    ds_cs_decay = xr.where(ds_cs[\"state\"] == \"decay\", ds_cs, np.nan)\n",
    "\n",
    "    # RMSE value\n",
    "    errors_base[f\"RMSE_{var}\"] = xs.rmse(ds_[f\"obs_{var}\"], ds_[f\"pred_{var}\"], dim=[\"track\", \"sample\"], skipna=True)\n",
    "    errors_state[\"growth\"][f\"RMSE_{var}\"] = xs.rmse(ds_cs_growth[f\"obs_{var}\"], ds_cs_growth[f\"pred_{var}\"], dim=[\"track\", \"sample\"], skipna=True)\n",
    "    errors_state[\"decay\"][f\"RMSE_{var}\"] = xs.rmse(ds_cs_decay[f\"obs_{var}\"], ds_cs_decay[f\"pred_{var}\"], dim=[\"track\", \"sample\"], skipna=True)\n",
    "\n",
    "    # MAE value\n",
    "    errors_base[f\"MAE_{var}\"] = xs.mae(ds_[f\"obs_{var}\"], ds_[f\"pred_{var}\"], dim=[\"track\", \"sample\"], skipna=True)\n",
    "    errors_state[\"growth\"][f\"MAE_{var}\"] = xs.mae(ds_cs_growth[f\"obs_{var}\"], ds_cs_growth[f\"pred_{var}\"], dim=[\"track\", \"sample\"], skipna=True)\n",
    "    errors_state[\"decay\"][f\"MAE_{var}\"] = xs.mae(ds_cs_decay[f\"obs_{var}\"], ds_cs_decay[f\"pred_{var}\"], dim=[\"track\", \"sample\"], skipna=True)\n",
    "\n",
    "    # ME value\n",
    "    errors_base[f\"ME_{var}\"] = xs.me(ds_[f\"obs_{var}\"], ds_[f\"pred_{var}\"], dim=[\"track\", \"sample\"], skipna=True)\n",
    "    errors_state[\"growth\"][f\"ME_{var}\"] = xs.me(ds_cs_growth[f\"obs_{var}\"], ds_cs_growth[f\"pred_{var}\"], dim=[\"track\", \"sample\"], skipna=True)\n",
    "    errors_state[\"decay\"][f\"ME_{var}\"] = xs.me(ds_cs_decay[f\"obs_{var}\"], ds_cs_decay[f\"pred_{var}\"], dim=[\"track\", \"sample\"], skipna=True)\n",
    "\n",
    "    # Bias ratio (mean(fct) / mean(obs))\n",
    "    errors_base[f\"BIAS_ratio_{var}\"] = ds_[f\"pred_{var}\"].mean(dim=[\"track\", \"sample\"]) / ds_[f\"obs_{var}\"].mean(dim=[\"track\", \"sample\"])\n",
    "    errors_state[\"growth\"][f\"BIAS_ratio_{var}\"] = ds_cs_growth[f\"pred_{var}\"].mean(dim=[\"track\", \"sample\"]) / ds_cs_growth[f\"obs_{var}\"].mean(dim=[\"track\", \"sample\"])\n",
    "    errors_state[\"decay\"][f\"BIAS_ratio_{var}\"] = ds_cs_decay[f\"pred_{var}\"].mean(dim=[\"track\", \"sample\"]) / ds_cs_decay[f\"obs_{var}\"].mean(dim=[\"track\", \"sample\"])\n",
    "\n",
    "# Turn into datasets\n",
    "ERRORS_BASE = xr.Dataset(errors_base)\n",
    "\n",
    "ERRORS_STATE = {}\n",
    "for k, d in errors_state.items():\n",
    "    ERRORS_STATE[k] = xr.Dataset(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\n",
    "    \"../config/stylefiles/article.mplstyle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors\n",
    "\n",
    "variables = [\"area\", \"mean_rr\", \"sum_rr\"]\n",
    "# errors = [\"MAE\", \"RMSE\", \"ME\"]\n",
    "errors = [\"RMSE\"]\n",
    "row = 0\n",
    "\n",
    "units = {\n",
    "    \"area\": \"km$^2$\",\n",
    "    \"mean_rr\": \"mm h$^{-1}$\",\n",
    "    \"sum_rr\": \"10$^6$ m$^3$h$^{-1}$\",\n",
    "}\n",
    "names = {\n",
    "    \"area\": \"area\",\n",
    "    \"sum_rr\": \"volume rain rate\",\n",
    "    \"mean_rr\": \"mean rainfall rate\",\n",
    "}\n",
    "ylims = {\n",
    "    \"MAE\": (0., 1.2),\n",
    "    \"RMSE\": (0, 2),\n",
    "    \"ME\": (-1.2, 1.2),\n",
    "    \"BIAS_ratio\": (0, 2),\n",
    "}\n",
    "major_locs = {\n",
    "    \"MAE\": 0.2,\n",
    "    \"RMSE\": 0.5,\n",
    "    \"ME\": 0.2,\n",
    "    \"BIAS_ratio\": 0.5,\n",
    "}\n",
    "minor_locs = {\n",
    "    \"MAE\": 0.05,\n",
    "    \"RMSE\": 0.1,\n",
    "    \"ME\": 0.05,\n",
    "    \"BIAS_ratio\": 0.1,\n",
    "}\n",
    "\n",
    "for var in variables:\n",
    "    for error in errors:\n",
    "        groups = list(errors_state.keys())\n",
    "        fig, axs = plt.subplots(\n",
    "            ncols=len(groups) + 1,\n",
    "            nrows=1,\n",
    "            # figsize=(W_PER_METHOD_S * N_METHODS, FIG_HEIGHT * len(groups)),\n",
    "            figsize=((FIG_WIDTH) * len(groups) + 1, FIG_HEIGHT*0.8 * 1),\n",
    "            constrained_layout=True,\n",
    "            sharey=\"row\",\n",
    "            squeeze=False\n",
    "        )\n",
    "        \n",
    "        \n",
    "        error_ = ERRORS_BASE[f\"{error}_{var}\"] \n",
    "        ax = axs[row, 0]\n",
    "        error_[\"leadtime_\"] = error_[\"leadtime\"] * 5\n",
    "        for model in conf.legend_order:\n",
    "            error_.sel(dict(method=model)).plot.line(\n",
    "                ax=ax,\n",
    "                x=\"leadtime_\",\n",
    "                color=conf.methods[model][\"color\"],\n",
    "                label=conf.methods[model][\"label\"],\n",
    "                linestyle=conf.methods[model][\"linestyle\"],\n",
    "            )\n",
    "        axs[row,0].set_title(f\"({alphabet[row * len(groups)]}) All cells\")\n",
    "        for i, name in enumerate(sorted(errors_state.keys())):\n",
    "            error_ = ERRORS_STATE[name][f\"{error}_{var}\"]\n",
    "        \n",
    "            ax = axs[row, i + 1]\n",
    "            error_[\"leadtime_\"] = error_[\"leadtime\"] * 5\n",
    "            for model in conf.legend_order:\n",
    "                error_.sel(dict(method=model)).plot.line(\n",
    "                    ax=ax,\n",
    "                    x=\"leadtime_\",\n",
    "                    color=conf.methods[model][\"color\"],\n",
    "                    label=conf.methods[model][\"label\"],\n",
    "                    linestyle=conf.methods[model][\"linestyle\"],\n",
    "                )\n",
    "            ax.set_title(f'({alphabet[row * len(groups) +1+i]}) {STATE_GROUP_TITLES[name]}', color=plt.rcParams[\"axes.titlecolor\"])\n",
    "    \n",
    "        for ax in axs[row].flatten():\n",
    "            metric_conf = conf.metric_conf[error]\n",
    "            metric_conf[\"ticks\"] = None\n",
    "            metric_conf[\"limits\"] = None\n",
    "            set_ax(ax, metric_conf, [5, 60], conf.leadtime_locator_multiples)\n",
    "            # ax.set_ylim(*ylims[error])\n",
    "            # ax.yaxis.set_major_locator(plt.MultipleLocator(major_locs[error]))\n",
    "            # ax.yaxis.set_minor_locator(plt.MultipleLocator(minor_locs[error]))\n",
    "            ax.set_ylabel(f\"{error} of {names[var]} [{units[var]}]\")\n",
    "            # ax.set_title(f'({alphabet[1+i]}) {conf.metric_conf[error][\"full_name\"]}', color=plt.rcParams[\"axes.titlecolor\"])\n",
    "            ax.grid(which=\"both\", axis=\"both\")\n",
    "\n",
    "            ax.axhline(0, **ZEROLINE_PROPS)\n",
    "            \n",
    "            ax.legend()\n",
    "            ax.label_outer()\n",
    "        \n",
    "        outputname = f\"error_{var}_{error}\"\n",
    "        save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)\n",
    "        del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store error values as csv\n",
    "error_growth = ERRORS_STATE[\"growth\"][f\"RMSE_sum_rr\"]\n",
    "ds_growth = error_growth.to_dataframe().reset_index()\n",
    "ds_growth[\"state\"] = \"growth\"\n",
    "ds_growth\n",
    "\n",
    "error_decay = ERRORS_STATE[\"decay\"][f\"RMSE_sum_rr\"]\n",
    "ds_decay = error_growth.to_dataframe().reset_index()\n",
    "ds_decay[\"state\"] = \"decay\"\n",
    "ds_decay\n",
    "\n",
    "error_all = ERRORS_BASE[f\"RMSE_sum_rr\"]\n",
    "ds_all = error_growth.to_dataframe().reset_index()\n",
    "ds_all[\"state\"] = \"all\"\n",
    "ds_all\n",
    "\n",
    "ds = pd.concat([ds_all, ds_decay, ds_growth])\n",
    "\n",
    "outputname = f\"error_sum_rr_RMSE\"\n",
    "ds.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area difference for all cells and by cell state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\n",
    "    \"../config/stylefiles/object_figs_article.mplstyle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_cs = DATASET_CELL_STATE[[\"pred_area\", \"obs_area\", \"area_diff\", \"state\", \"max_area\"]].where((DATASET_CELL_STATE[\"pred_area\"] > 0) & (DATASET_CELL_STATE[\"obs_area\"] > 0))\n",
    "ds_cs = ds_cs.to_dataframe().reset_index()\n",
    "ds_cs = ds_cs.drop_duplicates(subset=[\"sample\", \"track\", \"leadtime\", \"method\"])\n",
    "groups = ds_cs.groupby(\"state\")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=len(groups) + 1,\n",
    "    nrows=1,\n",
    "    # figsize=(W_PER_METHOD_S * N_METHODS, FIG_HEIGHT * len(groups)),\n",
    "    figsize=((FIG_WIDTH+0.2) * len(groups) + 1, FIG_HEIGHT * 1),\n",
    "    constrained_layout=True,\n",
    "    sharey=\"row\",\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "ds_ = DATASET_BASE[[\"pred_area\", \"obs_area\", \"area_diff\", \"max_area\"]].where((DATASET_BASE[\"pred_area\"] > 0) & (DATASET_BASE[\"obs_area\"] > 0))\n",
    "ds_ = ds_.to_dataframe().reset_index()\n",
    "ds_ = ds_.drop_duplicates(subset=[\"sample\", \"track\", \"leadtime\", \"method\"])\n",
    "\n",
    "g = sns.boxplot(\n",
    "    x=\"method\",\n",
    "    y=\"area_diff\",\n",
    "    order=conf.legend_order,\n",
    "    hue=\"leadtime\",\n",
    "    data=ds_,\n",
    "    ax=axs[0,0],\n",
    "    whis=[5, 95],\n",
    "    showfliers=True,\n",
    "    showmeans=True,\n",
    "    meanline=True,\n",
    "    medianprops=MEDIANPROPS,\n",
    "    meanprops=MEANLINEPROPS,\n",
    "    flierprops=FLIERPROPS,\n",
    "    legend=\"full\",\n",
    "    palette=HUE_CMAP,\n",
    ")\n",
    "axs[0,0].set_xticklabels([get_labelstr(l.get_text()) for l in axs[0,0].get_xticklabels()])\n",
    "g.axes.get_legend().remove()\n",
    "axs[0,0].set_title(\"(a) All cells\")\n",
    "\n",
    "for i, (name, group) in enumerate(groups):\n",
    "    ax = axs[0, 1 + i]\n",
    "    g = sns.boxplot(\n",
    "        x=\"method\",\n",
    "        y=\"area_diff\",\n",
    "        hue=\"leadtime\",\n",
    "        order=conf.legend_order,\n",
    "        data=group,\n",
    "        ax=ax,\n",
    "        whis=[5, 95],\n",
    "        showfliers=True,\n",
    "        showmeans=True,\n",
    "        meanline=True,\n",
    "        medianprops=MEDIANPROPS,\n",
    "        meanprops=MEANLINEPROPS,\n",
    "        flierprops=FLIERPROPS,\n",
    "        legend=\"full\",\n",
    "        palette=HUE_CMAP,\n",
    "    )\n",
    "    ax.set_title(f\"({alphabet[i+1]}) {STATE_GROUP_TITLES[name]}\")\n",
    "    ax.set_xticklabels(\n",
    "        [get_labelstr(l.get_text()) for l in ax.get_xticklabels()]\n",
    "    )\n",
    "    g.axes.get_legend().remove()\n",
    "\n",
    "for ax in axs.flatten():\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    # Add legend for mean and median lines\n",
    "\n",
    "    ax.set_ylabel(AREA_TITLE)\n",
    "    ax.set_ylim(AREA_LIMITS)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(AREA_TICK_MULTIPLE))\n",
    "    ax.grid(axis=\"y\")\n",
    "    ax.axhline(0, **ZEROLINE_PROPS)\n",
    "    ax.set_xlabel(METHOD_X_LABEL)\n",
    "    ax.yaxis.set_tick_params(which='both', labelbottom=True)\n",
    "\n",
    "medline = axs[0, 0].plot([], [], **MEDIANPROPS, label=\"Median\")\n",
    "meanline = axs[0, 0].plot([], [], **MEANLINEPROPS, label=\"Mean\")\n",
    "h, l = axs[0,0].get_legend_handles_labels()\n",
    "l1 = fig.legend(\n",
    "    h[:-2],\n",
    "    [leadtime_to_minutes((int(s)), 0) for s in l[:-2]],\n",
    "    title=\"Leadtime [min]\",\n",
    "    bbox_to_anchor=(0.27, 1.07, 0, 0),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=6,\n",
    "    # bbox_to_anchor=(0.7, 0.85),\n",
    "    # loc=\"upper left\",\n",
    "    # frameon=True,\n",
    "    # fancybox=True,\n",
    "    labelspacing=0.2,\n",
    "    # bbox_transform=fig.transFigure,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "l2 = fig.legend(\n",
    "    h[-2:],\n",
    "    l[-2:],\n",
    "    bbox_to_anchor=(0.25, 1.07, 0, 0),\n",
    "    loc=\"center right\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=1,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "fig.add_artist(l1)\n",
    "\n",
    "# axs[0, 1].remove()\n",
    "\n",
    "outputname = \"area_diff_article\"\n",
    "\n",
    "save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "store_df = pd.concat([ds_.groupby([\"leadtime\", \"method\"]).describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95])[\"area_diff\"], *[g.groupby([\"leadtime\", \"method\"]).describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95])[\"area_diff\"] for k, g in groups]], keys=[\"all\"] + [k for k, g in groups], axis=0).reset_index()\n",
    "store_df.rename(columns={\"level_0\": \"state\"}, inplace=True)\n",
    "\n",
    "outputname = \"area_diff_article\"\n",
    "store_df.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean rain rate difference for all cells and by cell state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_cs = DATASET_CELL_STATE[[\"pred_mean_rr\", \"obs_mean_rr\", \"mean_rr_diff\", \"state\"]].where((DATASET_CELL_STATE[\"pred_mean_rr\"] > 0) & (DATASET_CELL_STATE[\"obs_mean_rr\"] > 0))\n",
    "ds_cs = ds_cs.to_dataframe().reset_index()\n",
    "ds_cs = ds_cs.drop_duplicates(subset=[\"sample\", \"track\", \"leadtime\", \"method\"])\n",
    "groups = ds_cs.groupby(\"state\")\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=len(groups) + 1,\n",
    "    nrows=1,\n",
    "    # figsize=(W_PER_METHOD_S * N_METHODS, FIG_HEIGHT * len(groups)),\n",
    "    figsize=((FIG_WIDTH+0.2) * len(groups) + 1, FIG_HEIGHT * 1),\n",
    "    constrained_layout=True,\n",
    "    sharey=\"row\",\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "ds_ = DATASET_BASE[[\"pred_mean_rr\", \"obs_mean_rr\", \"mean_rr_diff\"]].where((DATASET_BASE[\"pred_mean_rr\"] > 0) & (DATASET_BASE[\"obs_mean_rr\"] > 0))\n",
    "ds_ = ds_.to_dataframe().reset_index()\n",
    "ds_ = ds_[(ds_[\"pred_mean_rr\"] > 0) & (ds_[\"obs_mean_rr\"] > 0)]\n",
    "ds_ = ds_.drop_duplicates(subset=[\"sample\", \"track\", \"leadtime\", \"method\"])\n",
    "\n",
    "g = sns.boxplot(\n",
    "    x=\"method\",\n",
    "    y=\"mean_rr_diff\",\n",
    "    hue=\"leadtime\",\n",
    "    order=conf.legend_order,\n",
    "    data=ds_,\n",
    "    ax=axs[0, 0],\n",
    "    whis=[5, 95],\n",
    "    showfliers=True,\n",
    "    showmeans=True,\n",
    "    meanline=True,\n",
    "    medianprops=MEDIANPROPS,\n",
    "    meanprops=MEANLINEPROPS,\n",
    "    flierprops=FLIERPROPS,\n",
    "    legend=\"full\",\n",
    "    palette=HUE_CMAP,\n",
    ")\n",
    "axs[0, 0].set_xticklabels([get_labelstr(l.get_text()) for l in axs[0, 0].get_xticklabels()])\n",
    "g.axes.get_legend().remove()\n",
    "\n",
    "axs[0, 0].set_autoscale_on(False)\n",
    "axs[0, 0].set_title(\"(a) All cells\")\n",
    "\n",
    "for i, (name, group) in enumerate(groups):\n",
    "    ax = axs[0, 1 + i]\n",
    "    g = sns.boxplot(\n",
    "        x=\"method\",\n",
    "        y=\"mean_rr_diff\",\n",
    "        hue=\"leadtime\",\n",
    "        order=conf.legend_order,\n",
    "        data=group,\n",
    "        ax=ax,\n",
    "        whis=[5, 95],\n",
    "        showfliers=True,\n",
    "        showmeans=True,\n",
    "        meanline=True,\n",
    "        medianprops=MEDIANPROPS,\n",
    "        meanprops=MEANLINEPROPS,\n",
    "        flierprops=FLIERPROPS,\n",
    "        legend=\"full\",\n",
    "        palette=HUE_CMAP,\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        [get_labelstr(l.get_text()) for l in ax.get_xticklabels()]\n",
    "    )\n",
    "    g.axes.get_legend().remove()\n",
    "    ax.set_title(f\"({alphabet[i+1]}) {STATE_GROUP_TITLES[name]}\")\n",
    "    \n",
    "    \n",
    "for ax in axs.flatten():\n",
    "    ax.set_autoscale_on(False)\n",
    "    ax.set_ylabel(MEAN_RR_DIFF_TITLE)\n",
    "    ax.set_ylim(MEAN_RR_LIMITS)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(MEAN_RR_TICK_MULTIPLE))\n",
    "    ax.grid(axis=\"y\")\n",
    "    ax.set_autoscale_on(False)\n",
    "    ax.axhline(0, **ZEROLINE_PROPS)\n",
    "    ax.set_xlabel(METHOD_X_LABEL)\n",
    "    ax.yaxis.set_tick_params(which='both', labelbottom=True)\n",
    "\n",
    "\n",
    "# Add legend for mean and median lines\n",
    "medline = axs[0,0].plot([], [], **MEDIANPROPS, label=\"Median\")\n",
    "meanline = axs[0,0].plot([], [], **MEANLINEPROPS, label=\"Mean\")\n",
    "\n",
    "h, l = axs[0,0].get_legend_handles_labels()\n",
    "l1 = fig.legend(\n",
    "    h[:-2],\n",
    "    [leadtime_to_minutes((int(s)), 0) for s in l[:-2]],\n",
    "    title=\"Leadtime [min]\",\n",
    "    bbox_to_anchor=(0.27, 1.07, 0, 0),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=6,\n",
    "    # bbox_to_anchor=(0.7, 0.85),\n",
    "    # loc=\"upper left\",\n",
    "    # frameon=True,\n",
    "    # fancybox=True,\n",
    "    labelspacing=0.2,\n",
    "    # bbox_transform=fig.transFigure,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "l2 = fig.legend(\n",
    "    h[-2:],\n",
    "    l[-2:],\n",
    "    bbox_to_anchor=(0.25, 1.07, 0, 0),\n",
    "    loc=\"center right\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=1,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "fig.add_artist(l1)\n",
    "                        \n",
    "# axs[0,1].remove()\n",
    "\n",
    "outputname = \"mean_rr_diff_article\"\n",
    "save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "store_df = pd.concat([ds_.groupby([\"leadtime\", \"method\"]).describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95])[\"mean_rr_diff\"], *[g.groupby([\"leadtime\", \"method\"]).describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95])[\"mean_rr_diff\"] for k, g in groups]], keys=[\"all\"] + [k for k, g in groups], axis=0).reset_index()\n",
    "store_df.rename(columns={\"level_0\": \"state\"}, inplace=True)\n",
    "\n",
    "outputname = \"mean_rr_diff_article\"\n",
    "store_df.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RVR difference for all cells and by cell state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_cs = DATASET_CELL_STATE[[\"pred_sum_rr\", \"obs_sum_rr\", \"sum_rr_diff\", \"state\"]].where((DATASET_CELL_STATE[\"pred_sum_rr\"] > 0) | (DATASET_CELL_STATE[\"obs_sum_rr\"] > 0))\n",
    "ds_cs = ds_cs.to_dataframe().reset_index()\n",
    "ds_cs = ds_cs.drop_duplicates(subset=[\"sample\", \"track\", \"leadtime\", \"method\"])\n",
    "groups = ds_cs.groupby(\"state\")\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=len(groups) + 1,\n",
    "    nrows=1,\n",
    "    # figsize=(W_PER_METHOD_S * N_METHODS, FIG_HEIGHT * len(groups)),\n",
    "    figsize=((FIG_WIDTH+0.2) * len(groups) + 1, FIG_HEIGHT * 1),\n",
    "    constrained_layout=True,\n",
    "    sharey=\"row\",\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "ds_ = DATASET_BASE[[\"pred_sum_rr\", \"obs_sum_rr\", \"sum_rr_diff\"]].where((DATASET_BASE[\"pred_sum_rr\"] > 0) | (DATASET_BASE[\"obs_sum_rr\"] > 0))\n",
    "ds_ = ds_.to_dataframe().reset_index()\n",
    "ds_ = ds_[(ds_[\"pred_sum_rr\"] > 0) & (ds_[\"obs_sum_rr\"] > 0)]\n",
    "ds_ = ds_.drop_duplicates(subset=[\"sample\", \"track\", \"leadtime\", \"method\"])\n",
    "\n",
    "g = sns.boxplot(\n",
    "    x=\"method\",\n",
    "    y=\"sum_rr_diff\",\n",
    "    hue=\"leadtime\",\n",
    "    order=conf.legend_order,\n",
    "    data=ds_,\n",
    "    ax=axs[0, 0],\n",
    "    whis=[5, 95],\n",
    "    showfliers=True,\n",
    "    showmeans=True,\n",
    "    meanline=True,\n",
    "    medianprops=MEDIANPROPS,\n",
    "    meanprops=MEANLINEPROPS,\n",
    "    flierprops=FLIERPROPS,\n",
    "    legend=\"full\",\n",
    "    palette=HUE_CMAP,\n",
    ")\n",
    "axs[0, 0].set_xticklabels([get_labelstr(l.get_text()) for l in axs[0, 0].get_xticklabels()])\n",
    "g.axes.get_legend().remove()\n",
    "\n",
    "axs[0, 0].set_autoscale_on(False)\n",
    "axs[0, 0].set_title(\"(a) All cells\")\n",
    "\n",
    "for i, (name, group) in enumerate(groups):\n",
    "    ax = axs[0, 1 + i]\n",
    "    g = sns.boxplot(\n",
    "        x=\"method\",\n",
    "        y=\"sum_rr_diff\",\n",
    "        hue=\"leadtime\",\n",
    "        order=conf.legend_order,\n",
    "        data=group,\n",
    "        ax=ax,\n",
    "        whis=[5, 95],\n",
    "        showfliers=True,\n",
    "        showmeans=True,\n",
    "        meanline=True,\n",
    "        medianprops=MEDIANPROPS,\n",
    "        meanprops=MEANLINEPROPS,\n",
    "        flierprops=FLIERPROPS,\n",
    "        legend=\"full\",\n",
    "        palette=HUE_CMAP,\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        [get_labelstr(l.get_text()) for l in ax.get_xticklabels()]\n",
    "    )\n",
    "    g.axes.get_legend().remove()\n",
    "    ax.set_title(f\"({alphabet[i+1]}) {STATE_GROUP_TITLES[name]}\")\n",
    "    \n",
    "for ax in axs.flatten():\n",
    "    ax.set_autoscale_on(False)\n",
    "    ax.set_ylabel(SUM_RR_DIFF_TITLE)\n",
    "    ax.set_ylim(SUM_RR_LIMITS)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(SUM_RR_TICK_MULTIPLE))\n",
    "    ax.grid(axis=\"y\")\n",
    "    ax.set_autoscale_on(False)\n",
    "    ax.axhline(0, **ZEROLINE_PROPS)\n",
    "    ax.set_xlabel(METHOD_X_LABEL)\n",
    "    ax.yaxis.set_tick_params(which='both', labelbottom=True)\n",
    "\n",
    "\n",
    "# Add legend for mean and median lines\n",
    "medline = axs[0,0].plot([], [], **MEDIANPROPS, label=\"Median\")\n",
    "meanline = axs[0,0].plot([], [], **MEANLINEPROPS, label=\"Mean\")\n",
    "\n",
    "h, l = axs[0,0].get_legend_handles_labels()\n",
    "l1 = fig.legend(\n",
    "    h[:-2],\n",
    "    [leadtime_to_minutes((int(s)), 0) for s in l[:-2]],\n",
    "    title=\"Leadtime [min]\",\n",
    "    bbox_to_anchor=(0.27, 1.07, 0, 0),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=6,\n",
    "    # bbox_to_anchor=(0.7, 0.85),\n",
    "    # loc=\"upper left\",\n",
    "    # frameon=True,\n",
    "    # fancybox=True,\n",
    "    labelspacing=0.2,\n",
    "    # bbox_transform=fig.transFigure,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "l2 = fig.legend(\n",
    "    h[-2:],\n",
    "    l[-2:],\n",
    "    bbox_to_anchor=(0.25, 1.07, 0, 0),\n",
    "    loc=\"center right\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=1,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "fig.add_artist(l1)\n",
    "                        \n",
    "# axs[0,1].remove()\n",
    "\n",
    "outputname = \"sum_rr_diff_article\"\n",
    "save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "store_df = pd.concat([ds_.groupby([\"leadtime\", \"method\"]).describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95])[\"sum_rr_diff\"], *[g.groupby([\"leadtime\", \"method\"]).describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95])[\"sum_rr_diff\"] for k, g in groups]], keys=[\"all\"] + [k for k, g in groups], axis=0).reset_index()\n",
    "store_df.rename(columns={\"level_0\": \"state\"}, inplace=True)\n",
    "\n",
    "outputname = \"sum_rr_diff_article\"\n",
    "store_df.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_cs = DATASET_CELL_STATE[[\"pred_sum_rr\", \"obs_sum_rr\", \"pred_dist\", \"state\"]].where((DATASET_CELL_STATE[\"pred_sum_rr\"] > 0) | (DATASET_CELL_STATE[\"obs_sum_rr\"] > 0))\n",
    "ds_cs = ds_cs.to_dataframe().reset_index()\n",
    "ds_cs = ds_cs.drop_duplicates(subset=[\"sample\", \"track\", \"leadtime\", \"method\"])\n",
    "groups = ds_cs.groupby(\"state\")\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=len(groups) + 1,\n",
    "    nrows=1,\n",
    "    # figsize=(W_PER_METHOD_S * N_METHODS, FIG_HEIGHT * len(groups)),\n",
    "    figsize=((FIG_WIDTH+0.2) * len(groups) + 1, FIG_HEIGHT * 1),\n",
    "    constrained_layout=True,\n",
    "    sharey=\"row\",\n",
    "    squeeze=False\n",
    ")\n",
    "\n",
    "ds_ = DATASET_BASE[[\"pred_sum_rr\", \"obs_sum_rr\", \"pred_dist\"]].where((DATASET_BASE[\"pred_sum_rr\"] > 0) | (DATASET_BASE[\"obs_sum_rr\"] > 0))\n",
    "ds_ = ds_.to_dataframe().reset_index()\n",
    "ds_ = ds_[(ds_[\"pred_sum_rr\"] > 0) & (ds_[\"obs_sum_rr\"] > 0)]\n",
    "ds_ = ds_.drop_duplicates(subset=[\"sample\", \"track\", \"leadtime\", \"method\"])\n",
    "\n",
    "g = sns.boxplot(\n",
    "    x=\"method\",\n",
    "    y=\"pred_dist\",\n",
    "    hue=\"leadtime\",\n",
    "    order=conf.legend_order,\n",
    "    data=ds_,\n",
    "    ax=axs[0, 0],\n",
    "    whis=[5, 95],\n",
    "    showfliers=True,\n",
    "    showmeans=True,\n",
    "    meanline=True,\n",
    "    medianprops=MEDIANPROPS,\n",
    "    meanprops=MEANLINEPROPS,\n",
    "    flierprops=FLIERPROPS,\n",
    "    legend=\"full\",\n",
    "    palette=HUE_CMAP,\n",
    ")\n",
    "axs[0, 0].set_xticklabels([get_labelstr(l.get_text()) for l in axs[0, 0].get_xticklabels()])\n",
    "g.axes.get_legend().remove()\n",
    "\n",
    "axs[0, 0].set_autoscale_on(False)\n",
    "axs[0, 0].set_title(\"(a) All cells\")\n",
    "\n",
    "\n",
    "for i, (name, group) in enumerate(groups):\n",
    "    ax = axs[0, 1 + i]\n",
    "    g = sns.boxplot(\n",
    "        x=\"method\",\n",
    "        y=\"pred_dist\",\n",
    "        hue=\"leadtime\",\n",
    "        order=conf.legend_order,\n",
    "        data=group,\n",
    "        ax=ax,\n",
    "        whis=[5, 95],\n",
    "        showfliers=True,\n",
    "        showmeans=True,\n",
    "        meanline=True,\n",
    "        medianprops=MEDIANPROPS,\n",
    "        meanprops=MEANLINEPROPS,\n",
    "        flierprops=FLIERPROPS,\n",
    "        legend=\"full\",\n",
    "        palette=HUE_CMAP,\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        [get_labelstr(l.get_text()) for l in ax.get_xticklabels()]\n",
    "    )\n",
    "    g.axes.get_legend().remove()\n",
    "    ax.set_title(f\"({alphabet[i+1]}) {STATE_GROUP_TITLES[name]}\")\n",
    "    \n",
    "for ax in axs.flatten():\n",
    "    ax.set_autoscale_on(False)\n",
    "    ax.set_ylabel(CENTROID_DISTANCE_TITLE)\n",
    "    ax.set_ylim(CENTROID_DISTANCE_LIMITS)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "    ax.grid(axis=\"y\")\n",
    "    ax.set_autoscale_on(False)\n",
    "    ax.axhline(0, **ZEROLINE_PROPS)\n",
    "    ax.set_xlabel(METHOD_X_LABEL)\n",
    "\n",
    "\n",
    "# Add legend for mean and median lines\n",
    "medline = axs[0,0].plot([], [], **MEDIANPROPS, label=\"Median\")\n",
    "meanline = axs[0,0].plot([], [], **MEANLINEPROPS, label=\"Mean\")\n",
    "\n",
    "h, l = axs[0,0].get_legend_handles_labels()\n",
    "l1 = fig.legend(\n",
    "    h[:-2],\n",
    "    [leadtime_to_minutes((int(s)), 0) for s in l[:-2]],\n",
    "    title=\"Leadtime [min]\",\n",
    "    bbox_to_anchor=(0.27, 1.07, 0, 0),\n",
    "    loc=\"center left\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=6,\n",
    "    # bbox_to_anchor=(0.7, 0.85),\n",
    "    # loc=\"upper left\",\n",
    "    # frameon=True,\n",
    "    # fancybox=True,\n",
    "    labelspacing=0.2,\n",
    "    # bbox_transform=fig.transFigure,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "l2 = fig.legend(\n",
    "    h[-2:],\n",
    "    l[-2:],\n",
    "    bbox_to_anchor=(0.25, 1.07, 0, 0),\n",
    "    loc=\"center right\",\n",
    "    frameon=True,\n",
    "    bbox_transform=fig.transFigure,\n",
    "    ncols=1,\n",
    "    fontsize=\"large\",\n",
    "    title_fontsize=\"large\",\n",
    ")\n",
    "fig.add_artist(l1)\n",
    "                        \n",
    "# axs[0,1].remove()\n",
    "\n",
    "outputname = \"centroid_distance_article\"\n",
    "save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "store_df = pd.concat([ds_.groupby([\"leadtime\", \"method\"]).describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95])[\"pred_dist\"], *[g.groupby([\"leadtime\", \"method\"]).describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95])[\"pred_dist\"] for k, g in groups]], keys=[\"all\"] + [k for k, g in groups], axis=0).reset_index()\n",
    "store_df.rename(columns={\"level_0\": \"state\"}, inplace=True)\n",
    "\n",
    "outputname = \"centroid_distance_article\"\n",
    "store_df.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del ds_cs, ds_, groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions of variables for all cells and by cell state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"../config/stylefiles/article.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_cs = DATASET_CELL_STATE[[\"track_max_prev_rr\", \"track_max_obs_rr\", \"state\", \"max_area\", \"prev_sum_rr\", \"prev_mean_rr\", \"prev_area\", \"prev_mean_rr\", \"lifetime_full\"]]\n",
    "ds_cs = ds_cs.to_dataframe().reset_index()\n",
    "ds_cs = ds_cs.drop_duplicates(subset=[\"sample\", \"track\", \"prev_time\"])\n",
    "\n",
    "ds_cs = ds_cs[ds_cs[\"prev_time\"] == 0]\n",
    "\n",
    "groups = ds_cs.groupby(\"state\")\n",
    "\n",
    "ds_ = DATASET_BASE[[\"track_max_prev_rr\", \"track_max_obs_rr\", \"max_area\", \"prev_sum_rr\", \"prev_mean_rr\", \"prev_area\", \"prev_mean_rr\", \"lifetime_full\"]]\n",
    "ds_ = ds_.to_dataframe().reset_index()\n",
    "ds_ = ds_.drop_duplicates(subset=[\"sample\", \"track\", \"prev_time\"])\n",
    "ds_ = ds_[(ds_[\"prev_time\"] == 0) & (ds_[\"track_max_prev_rr\"] > 0) & (ds_[\"prev_sum_rr\"] > 0)]\n",
    "\n",
    "variables = [\n",
    "    \"prev_sum_rr\", \n",
    "    \"prev_area\", \n",
    "    \"max_area\", \n",
    "    \"lifetime_full\",\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    ncols=len(groups)+1,\n",
    "    nrows=len(variables),\n",
    "    # figsize=(W_PER_METHOD_S * N_METHODS, FIG_HEIGHT * len(groups)),\n",
    "    figsize=(HIST_FIG_W * (len(groups)+1), HIST_FIG_H * len(variables) + 0.3),\n",
    "    layout='compressed',\n",
    "    sharey=\"row\",\n",
    "    sharex=\"row\",\n",
    "    squeeze=True\n",
    ")\n",
    "\n",
    "\n",
    "bin_ranges = {\n",
    "    \"prev_mean_rr\": (0, 50),\n",
    "    \"prev_max_rr\": (0, 150),\n",
    "    \"prev_area\": (0, 1600),\n",
    "    \"lifetime_full\": (0, 15),\n",
    "    \"max_area\": (0, 1600),\n",
    "    \"prev_sum_rr\": (0, 200),\n",
    "    \"sum_rr_diff\": (-200, 400),\n",
    "    \"track_max_obs_rr\": (0, 200),\n",
    "}\n",
    "nbins = {\n",
    "    \"prev_mean_rr\": 50,\n",
    "    \"prev_max_rr\": 50,\n",
    "    \"prev_area\": 160,\n",
    "    \"lifetime_full\": 15,\n",
    "    \"max_area\": 160,\n",
    "    \"prev_sum_rr\": 400,\n",
    "    \"sum_rr_diff\": 600,\n",
    "    \"track_max_obs_rr\": 400,\n",
    "}\n",
    "\n",
    "titles = {\n",
    "    \"prev_mean_rr\": \"$R_\\mathrm{avg}$($t_0$)\",\n",
    "    \"prev_max_rr\": \"$R_\\mathrm{max}$($t_0$)\",\n",
    "    \"prev_area\": \"$A(t_0)$\",\n",
    "    \"lifetime_full\": \"lifetime $L$\",\n",
    "    \"max_area\": \"$A_\\mathrm{max}$\",\n",
    "    \"prev_sum_rr\": \"RVR($t_0$)\",\n",
    "    \"sum_rr_diff\": \"\",\n",
    "    \"track_max_obs_rr\": \"RVR$_\\mathrm{max, target}$\",\n",
    "}\n",
    "\n",
    "discrete = {\n",
    "    \"prev_mean_rr\": False,\n",
    "    \"prev_max_rr\": False,\n",
    "    \"prev_area\": False,\n",
    "    \"lifetime_full\": True,\n",
    "    \"max_area\": False,\n",
    "    \"prev_sum_rr\": False,\n",
    "    \"track_max_obs_rr\": False,\n",
    "}\n",
    "\n",
    "count_loc = (0.95, 0.95)\n",
    "props = dict(facecolor='white', alpha=0.5)\n",
    "\n",
    "histograms = {}\n",
    "\n",
    "for row, var in enumerate(variables):\n",
    "    g = sns.histplot(\n",
    "        data=ds_,\n",
    "        x=var,\n",
    "        ax=axs[row, 0],\n",
    "        stat=\"percent\",\n",
    "        color=\"k\",\n",
    "        bins=nbins[var],\n",
    "        binrange=bin_ranges[var],\n",
    "        discrete=discrete[var],\n",
    "    )\n",
    "    histograms[var] = {}\n",
    "    # Save histogram\n",
    "    hist, bins = np.histogram(ds_[var], bins=nbins[var], range=bin_ranges[var])\n",
    "    histograms[var][\"all\"] = pd.DataFrame(hist,  index=bins[:-1], columns=[\"count\"])\n",
    "\n",
    "    num_obs = ds_.count()[var]\n",
    "    # Add label with number of observations\n",
    "    axs[row, 0].text(\n",
    "        *count_loc,\n",
    "        f\"N = {num_obs:,d}\",\n",
    "        horizontalalignment=\"right\",\n",
    "        verticalalignment=\"top\",\n",
    "        transform=axs[row, 0].transAxes,\n",
    "        fontsize=\"medium\",\n",
    "        bbox=props,\n",
    "    )\n",
    "    axs[row, 0].set_title(f\"({alphabet[3*row]}) All cells: {titles[var]}\", fontsize=\"medium\")\n",
    "    \n",
    "    for i, (name, group) in enumerate(groups):\n",
    "        # Plot distribution\n",
    "        g = sns.histplot(\n",
    "            data=group,\n",
    "            x=var,\n",
    "            ax=axs[row, 1+i],\n",
    "            stat=\"percent\",\n",
    "            color=\"k\",\n",
    "            bins=nbins[var],\n",
    "            binrange=bin_ranges[var],\n",
    "            discrete=discrete[var],\n",
    "        )\n",
    "        hist, bins = np.histogram(group[var], bins=nbins[var], range=bin_ranges[var])\n",
    "        histograms[var][name] = pd.DataFrame(hist,  index=bins[:-1], columns=[\"count\"])\n",
    "        \n",
    "        num_obs = group.count()[var]\n",
    "        # Add label with number of observations\n",
    "        axs[row, 1+i].text(\n",
    "            *count_loc,\n",
    "            f\"N = {num_obs:,d}\",\n",
    "            horizontalalignment=\"right\",\n",
    "            verticalalignment=\"top\",\n",
    "            transform=axs[row, 1+i].transAxes,\n",
    "            fontsize=\"medium\",\n",
    "            bbox=props,\n",
    "        )\n",
    "        axs[row, 1+i].set_title(f\"({alphabet[3*row+i+1]}) {STATE_GROUP_TITLES[name]}: {titles[var]}\", fontsize=\"medium\")\n",
    "\n",
    "# axis for rain rate sum\n",
    "for ax in axs[variables.index(\"prev_sum_rr\"), :].flatten():\n",
    "    ax.set_ylabel(\"Proportion [%]\")\n",
    "    ax.set_ylim([0, 25])\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))\n",
    "    ax.grid(axis=\"y\")\n",
    "    ax.set_xlim((0, 20))\n",
    "    ax.set_xlabel(\"Volume rain rate [10$^6$ m$^3$h$^{-1}$]\")\n",
    "    \n",
    "# axis for area\n",
    "for ax in axs[variables.index(\"prev_area\"), :].flatten():\n",
    "    ax.set_ylabel(\"Proportion [%]\")\n",
    "    ax.set_ylim([0, 10])\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(250))\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(50))\n",
    "    ax.grid(axis=\"y\")\n",
    "    ax.set_xlim((0, 1600))\n",
    "    # Vertical line at 25\n",
    "    ax.axvline(25, linestyle=\"--\", color=\"k\", linewidth=1.5)\n",
    "    ax.set_xlabel(\"Cell area [km$^2$]\")\n",
    "    \n",
    "# axis for area\n",
    "for ax in axs[variables.index(\"max_area\"), :].flatten():\n",
    "    ax.set_ylabel(\"Proportion [%]\")\n",
    "    ax.set_ylim([0, 10])\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(250))\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(50))\n",
    "    ax.grid(axis=\"y\")\n",
    "    ax.set_xlim((0, 1600))\n",
    "    # Vertical line at 25\n",
    "    ax.axvline(25, linestyle=\"--\", color=\"k\", linewidth=1.5)\n",
    "    ax.set_xlabel(\"Cell area [km$^2$]\")\n",
    "    \n",
    "# axis for lifetime\n",
    "for ax in axs[variables.index(\"lifetime_full\"), :].flatten():\n",
    "    ax.set_ylabel(\"Proportion [%]\")\n",
    "    ax.set_ylim([0, 30])\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(1))\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(leadtime_to_minutes))\n",
    "    ax.grid(axis=\"y\")\n",
    "    ax.set_xlim((0.5, 15.5))\n",
    "    ax.set_xlabel(\"Track lifetime [min]\")\n",
    "    \n",
    "# Add some space between rows\n",
    "# fig.get_layout_engine().set(hspace=0.05)\n",
    "\n",
    "outputname = \"histograms_article\"\n",
    "save_figs(fig, OUTPUT_DIR, outputname, conf.output_formats)\n",
    "\n",
    "# Save histograms\n",
    "for var in variables:\n",
    "    store_df = pd.concat(histograms[var].values(), keys=histograms[var].keys(), axis=0)\n",
    "    store_df = store_df.reset_index().rename(columns={\"level_0\": \"state\", \"level_1\": \"value\"})\n",
    "    outputname = f\"histograms_article_{var}\"\n",
    "    store_df.to_csv(OUTPUT_DIR / f\"{outputname}.csv\")\n",
    "\n",
    "# Free up memory\n",
    "# del ds_cs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
